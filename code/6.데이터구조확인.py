"""
ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ - ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° ê²°ê³¼ë¬¼ í´ë” ì„¤ì •
ìƒì„±ì¼: 2025-06-08
íŒ€: í˜„ì¢…ë¯¼(íŒ€ì¥), ì‹ ì˜ˆì›(íŒ€ì›), ê¹€ì±„ì€(íŒ€ì›)
ëª©ì : í”„ë¡œì íŠ¸ ë°ì´í„° êµ¬ì¡° ë¶„ì„ ë° ì²´ê³„ì ì¸ ê²°ê³¼ë¬¼ ê´€ë¦¬ ì‹œìŠ¤í…œ êµ¬ì¶•
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import glob
import warnings
warnings.filterwarnings('ignore')

# ê²°ê³¼ë¬¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
RESULTS_BASE = "/Users/jm/Desktop/ì¶©ë¶ëŒ€í•™êµ/ì¶©ëŒ€ 4í•™ë…„ 1í•™ê¸°/2. ë¹…ë°ì´í„°ì´í•´ì™€ë¶„ì„/íŒ€í”„ë¡œì íŠ¸/trend-prediction-model/results/2025-0608"
PROJECT_BASE = "/Users/jm/Desktop/ì¶©ë¶ëŒ€í•™êµ/ì¶©ëŒ€ 4í•™ë…„ 1í•™ê¸°/2. ë¹…ë°ì´í„°ì´í•´ì™€ë¶„ì„/íŒ€í”„ë¡œì íŠ¸/trend-prediction-model"

# í•œê¸€ í°íŠ¸ ì„¤ì • (macOS)
plt.rcParams['font.family'] = ['Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

def setup_directories():
    """ê²°ê³¼ë¬¼ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
    directories = [
        f"{RESULTS_BASE}/visualizations/weekly_analysis",
        f"{RESULTS_BASE}/visualizations/impact_analysis", 
        f"{RESULTS_BASE}/visualizations/model_performance",
        f"{RESULTS_BASE}/visualizations/final_insights",
        f"{RESULTS_BASE}/data/processed",
        f"{RESULTS_BASE}/data/features",
        f"{RESULTS_BASE}/data/predictions", 
        f"{RESULTS_BASE}/data/exports",
        f"{RESULTS_BASE}/models/trained",
        f"{RESULTS_BASE}/models/evaluation",
        f"{RESULTS_BASE}/models/features_importance",
        f"{RESULTS_BASE}/models/predictions",
        f"{RESULTS_BASE}/reports/technical",
        f"{RESULTS_BASE}/reports/business",
        f"{RESULTS_BASE}/reports/methodology",
        f"{RESULTS_BASE}/reports/final"
    ]
    
    for dir_path in directories:
        os.makedirs(dir_path, exist_ok=True)
    
    print(f"âœ… ê²°ê³¼ë¬¼ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ: {RESULTS_BASE}")
    return directories

class DataStructureAnalyzer:
    """í”„ë¡œì íŠ¸ ë°ì´í„° êµ¬ì¡° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, project_base_path):
        self.project_base = project_base_path
        self.stock_path = f"{project_base_path}/stock"
        self.product_path = f"{project_base_path}/product"
        self.data_path = f"{project_base_path}/data"
        self.code_path = f"{project_base_path}/code"
        
        self.analysis_results = {}
        
    def analyze_directory_structure(self):
        """í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„"""
        print("ğŸ—‚ï¸ í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„")
        print("=" * 50)
        
        # ê¸°ë³¸ ë””ë ‰í† ë¦¬ë“¤ í™•ì¸
        base_dirs = ['stock', 'product', 'data', 'code', 'results']
        existing_dirs = []
        missing_dirs = []
        
        for dir_name in base_dirs:
            dir_path = f"{self.project_base}/{dir_name}"
            if os.path.exists(dir_path):
                existing_dirs.append(dir_name)
                print(f"âœ… {dir_name}/ - ì¡´ì¬")
            else:
                missing_dirs.append(dir_name)
                print(f"âŒ {dir_name}/ - ëˆ„ë½")
        
        self.analysis_results['directory_structure'] = {
            'existing': existing_dirs,
            'missing': missing_dirs
        }
        
        return existing_dirs, missing_dirs
    
    def analyze_stock_data(self):
        """ì£¼ê°€ ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
        print("\nğŸ“ˆ ì£¼ê°€ ë°ì´í„° êµ¬ì¡° ë¶„ì„")
        print("=" * 50)
        
        stock_files = glob.glob(f"{self.stock_path}/*.csv")
        print(f"ì£¼ê°€ ë°ì´í„° íŒŒì¼ ìˆ˜: {len(stock_files)}")
        
        stock_analysis = {}
        
        for file_path in stock_files:
            file_name = os.path.basename(file_path)
            print(f"\nğŸ“ {file_name}")
            
            try:
                df = pd.read_csv(file_path)
                
                # ê¸°ë³¸ ì •ë³´
                analysis = {
                    'file_size': f"{os.path.getsize(file_path) / 1024:.1f} KB",
                    'rows': len(df),
                    'columns': list(df.columns),
                    'date_range': None,
                    'sample_data': df.head(3).to_dict('records')
                }
                
                # ë‚ ì§œ ì»¬ëŸ¼ ì°¾ê¸° ë° ë¶„ì„
                date_cols = [col for col in df.columns if 'date' in col.lower() or 'ì¼ì' in col]
                if date_cols:
                    date_col = date_cols[0]
                    try:
                        df[date_col] = pd.to_datetime(df[date_col])
                        analysis['date_range'] = {
                            'start': str(df[date_col].min().date()),
                            'end': str(df[date_col].max().date()),
                            'days': (df[date_col].max() - df[date_col].min()).days
                        }
                    except:
                        analysis['date_range'] = "ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨"
                
                # ì¶œë ¥
                print(f"  - í¬ê¸°: {analysis['file_size']}")
                print(f"  - í–‰ìˆ˜: {analysis['rows']:,}")
                print(f"  - ì»¬ëŸ¼: {analysis['columns']}")
                if analysis['date_range'] and isinstance(analysis['date_range'], dict):
                    print(f"  - ê¸°ê°„: {analysis['date_range']['start']} ~ {analysis['date_range']['end']}")
                    print(f"  - ì¼ìˆ˜: {analysis['date_range']['days']}ì¼")
                
                stock_analysis[file_name] = analysis
                
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {str(e)}")
                stock_analysis[file_name] = {'error': str(e)}
        
        self.analysis_results['stock_data'] = stock_analysis
        return stock_analysis
    
    def analyze_sentiment_data(self):
        """ê°ì„± ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
        print("\nğŸ­ ê°ì„± ë°ì´í„° êµ¬ì¡° ë¶„ì„")
        print("=" * 50)
        
        # ê¸°ì¡´ ê°ì„± ë°ì´í„° íŒŒì¼ë“¤ ì°¾ê¸°
        sentiment_files = []
        
        # data í´ë”ì—ì„œ ì°¾ê¸°
        if os.path.exists(self.data_path):
            sentiment_files.extend(glob.glob(f"{self.data_path}/**/*.csv", recursive=True))
        
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì°¾ê¸°
        sentiment_files.extend(glob.glob(f"{self.project_base}/*.csv"))
        
        # ê°ì„± ê´€ë ¨ íŒŒì¼ í•„í„°ë§
        sentiment_files = [f for f in sentiment_files if any(keyword in os.path.basename(f).lower() 
                          for keyword in ['samsung', 'apple', 'ì‚¼ì„±', 'ê°ì„±', 'sentiment'])]
        
        print(f"ê°ì„± ë°ì´í„° íŒŒì¼ ìˆ˜: {len(sentiment_files)}")
        
        sentiment_analysis = {}
        
        for file_path in sentiment_files:
            file_name = os.path.basename(file_path)
            print(f"\nğŸ“ {file_name}")
            
            try:
                # íŒŒì¼ í¬ê¸° í™•ì¸ (í° íŒŒì¼ì€ ìƒ˜í”Œë§Œ ì½ê¸°)
                file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
                
                if file_size_mb > 100:  # 100MB ì´ìƒ
                    df = pd.read_csv(file_path, nrows=10000)  # ìƒ˜í”Œë§Œ ì½ê¸°
                    print(f"  âš ï¸ í° íŒŒì¼ ({file_size_mb:.1f}MB) - ìƒ˜í”Œ 10,000í–‰ë§Œ ë¶„ì„")
                else:
                    df = pd.read_csv(file_path)
                
                # ê¸°ë³¸ ì •ë³´
                analysis = {
                    'file_size': f"{file_size_mb:.1f} MB",
                    'rows': len(df),
                    'columns': list(df.columns),
                    'sample_data': df.head(3).to_dict('records')
                }
                
                # ê°ì„± ê´€ë ¨ ì»¬ëŸ¼ ì°¾ê¸°
                sentiment_cols = [col for col in df.columns if any(keyword in col.lower() 
                                for keyword in ['ê°ì •', 'ê°ì„±', 'sentiment', 'ì ìˆ˜', 'score'])]
                if sentiment_cols:
                    analysis['sentiment_columns'] = sentiment_cols
                    
                    # ê°ì„± ì ìˆ˜ ë¶„í¬ ë¶„ì„
                    for col in sentiment_cols:
                        if df[col].dtype in ['int64', 'float64']:
                            analysis[f'{col}_stats'] = {
                                'min': float(df[col].min()),
                                'max': float(df[col].max()),
                                'mean': float(df[col].mean()),
                                'unique_values': int(df[col].nunique())
                            }
                
                # ë‚ ì§œ ì»¬ëŸ¼ ë¶„ì„
                date_cols = [col for col in df.columns if 'date' in col.lower() or 'ì¼ì' in col]
                if date_cols:
                    analysis['date_columns'] = date_cols
                
                # ì¶œë ¥
                print(f"  - í¬ê¸°: {analysis['file_size']}")
                print(f"  - í–‰ìˆ˜: {analysis['rows']:,}")
                print(f"  - ì»¬ëŸ¼: {analysis['columns']}")
                if 'sentiment_columns' in analysis:
                    print(f"  - ê°ì„± ì»¬ëŸ¼: {analysis['sentiment_columns']}")
                
                sentiment_analysis[file_name] = analysis
                
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {str(e)}")
                sentiment_analysis[file_name] = {'error': str(e)}
        
        self.analysis_results['sentiment_data'] = sentiment_analysis
        return sentiment_analysis
    
    def analyze_product_data(self):
        """ì œí’ˆ ì¶œì‹œ ë°ì´í„° êµ¬ì¡° ë¶„ì„"""
        print("\nğŸ“± ì œí’ˆ ì¶œì‹œ ë°ì´í„° êµ¬ì¡° ë¶„ì„")
        print("=" * 50)
        
        if not os.path.exists(self.product_path):
            print("âŒ product í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return {}
        
        product_files = glob.glob(f"{self.product_path}/*")
        print(f"ì œí’ˆ ì¶œì‹œ ê´€ë ¨ íŒŒì¼ ìˆ˜: {len(product_files)}")
        
        product_analysis = {}
        
        for file_path in product_files:
            file_name = os.path.basename(file_path)
            print(f"\nğŸ“ {file_name}")
            
            try:
                if file_path.endswith('.csv'):
                    df = pd.read_csv(file_path)
                    analysis = {
                        'type': 'CSV',
                        'rows': len(df),
                        'columns': list(df.columns),
                        'sample_data': df.head(3).to_dict('records')
                    }
                elif file_path.endswith(('.txt', '.md')):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    analysis = {
                        'type': 'TEXT',
                        'lines': len(content.split('\n')),
                        'characters': len(content),
                        'preview': content[:200] + "..." if len(content) > 200 else content
                    }
                else:
                    analysis = {
                        'type': 'OTHER',
                        'file_size': f"{os.path.getsize(file_path) / 1024:.1f} KB"
                    }
                
                print(f"  - íƒ€ì…: {analysis['type']}")
                if 'rows' in analysis:
                    print(f"  - í–‰ìˆ˜: {analysis['rows']:,}")
                if 'columns' in analysis:
                    print(f"  - ì»¬ëŸ¼: {analysis['columns']}")
                
                product_analysis[file_name] = analysis
                
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜: {str(e)}")
                product_analysis[file_name] = {'error': str(e)}
        
        self.analysis_results['product_data'] = product_analysis
        return product_analysis
    
    def create_data_overview_visualization(self):
        """ë°ì´í„° ê°œìš” ì‹œê°í™” ìƒì„±"""
        print("\nğŸ“Š ë°ì´í„° ê°œìš” ì‹œê°í™” ìƒì„±")
        print("=" * 50)
        
        # 2x2 ì„œë¸Œí”Œë¡¯ ìƒì„±
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('Project Data Structure Overview', fontsize=16, fontweight='bold')
        
        # 1. ë””ë ‰í† ë¦¬ êµ¬ì¡° (íŒŒì´ ì°¨íŠ¸)
        ax1 = axes[0, 0]
        if 'directory_structure' in self.analysis_results:
            existing = len(self.analysis_results['directory_structure']['existing'])
            missing = len(self.analysis_results['directory_structure']['missing'])
            
            labels = ['Existing Directories', 'Missing Directories']
            sizes = [existing, missing]
            colors = ['#2ecc71', '#e74c3c']
            
            ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
            ax1.set_title('Directory Structure Status')
        
        # 2. íŒŒì¼ íƒ€ì…ë³„ ë¶„í¬ (ë§‰ëŒ€ ì°¨íŠ¸)
        ax2 = axes[0, 1]
        file_types = {'Stock Files': 0, 'Sentiment Files': 0, 'Product Files': 0}
        
        if 'stock_data' in self.analysis_results:
            file_types['Stock Files'] = len(self.analysis_results['stock_data'])
        if 'sentiment_data' in self.analysis_results:
            file_types['Sentiment Files'] = len(self.analysis_results['sentiment_data'])
        if 'product_data' in self.analysis_results:
            file_types['Product Files'] = len(self.analysis_results['product_data'])
        
        bars = ax2.bar(file_types.keys(), file_types.values(), 
                      color=['#3498db', '#9b59b6', '#f39c12'])
        ax2.set_title('File Type Distribution')
        ax2.set_ylabel('Number of Files')
        
        # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
        for bar in bars:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{int(height)}', ha='center', va='bottom')
        
        # 3. ë°ì´í„° í¬ê¸° ë¶„ì„ (ê°€ë¡œ ë§‰ëŒ€ ì°¨íŠ¸)
        ax3 = axes[1, 0]
        data_sizes = []
        labels = []
        
        # ì£¼ê°€ ë°ì´í„° í¬ê¸°
        if 'stock_data' in self.analysis_results:
            for file_name, info in self.analysis_results['stock_data'].items():
                if 'rows' in info:
                    data_sizes.append(info['rows'])
                    labels.append(f"Stock: {file_name[:15]}...")
        
        # ê°ì„± ë°ì´í„° í¬ê¸°
        if 'sentiment_data' in self.analysis_results:
            for file_name, info in self.analysis_results['sentiment_data'].items():
                if 'rows' in info:
                    data_sizes.append(info['rows'])
                    labels.append(f"Sentiment: {file_name[:15]}...")
        
        if data_sizes:
            y_pos = np.arange(len(labels))
            ax3.barh(y_pos, data_sizes, color='#1abc9c')
            ax3.set_yticks(y_pos)
            ax3.set_yticklabels(labels, fontsize=8)
            ax3.set_xlabel('Number of Rows')
            ax3.set_title('Data Size Comparison')
        
        # 4. í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™© (í…ìŠ¤íŠ¸ ìš”ì•½)
        ax4 = axes[1, 1]
        ax4.axis('off')
        
        summary_text = f"""
PROJECT ANALYSIS SUMMARY

ğŸ“ Directories: {len(self.analysis_results.get('directory_structure', {}).get('existing', []))} found
ğŸ“ˆ Stock Files: {len(self.analysis_results.get('stock_data', {}))} files
ğŸ­ Sentiment Files: {len(self.analysis_results.get('sentiment_data', {}))} files  
ğŸ“± Product Files: {len(self.analysis_results.get('product_data', {}))} files

STATUS: Data structure analysis completed
NEXT: Proceed with 7-day average visualization
        """
        
        ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, 
                fontsize=10, verticalalignment='top',
                bbox=dict(boxstyle="round,pad=0.3", facecolor='lightgray', alpha=0.5))
        
        plt.tight_layout()
        
        # ì‹œê°í™” ì €ì¥
        viz_path = f"{RESULTS_BASE}/visualizations/weekly_analysis/data_overview.png"
        plt.savefig(viz_path, dpi=300, bbox_inches='tight', facecolor='white')
        print(f"âœ… ë°ì´í„° ê°œìš” ì‹œê°í™” ì €ì¥: {viz_path}")
        
        plt.show()
        
    def save_analysis_report(self):
        """ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸ ì €ì¥"""
        print("\nğŸ“„ ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸ ì €ì¥")
        print("=" * 50)
        
        # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
        report_content = f"""# ë°ì´í„° êµ¬ì¡° ë¶„ì„ ë¦¬í¬íŠ¸

## ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M')}
## íŒ€: í˜„ì¢…ë¯¼(íŒ€ì¥), ì‹ ì˜ˆì›(íŒ€ì›), ê¹€ì±„ì€(íŒ€ì›)

---

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡° ë¶„ì„

### ì¡´ì¬í•˜ëŠ” ë””ë ‰í† ë¦¬
"""
        
        if 'directory_structure' in self.analysis_results:
            for dir_name in self.analysis_results['directory_structure']['existing']:
                report_content += f"- âœ… {dir_name}/\n"
            
            if self.analysis_results['directory_structure']['missing']:
                report_content += "\n### ëˆ„ë½ëœ ë””ë ‰í† ë¦¬\n"
                for dir_name in self.analysis_results['directory_structure']['missing']:
                    report_content += f"- âŒ {dir_name}/\n"
        
        # ì£¼ê°€ ë°ì´í„° ë¶„ì„ ê²°ê³¼
        if 'stock_data' in self.analysis_results:
            report_content += f"\n## ğŸ“ˆ ì£¼ê°€ ë°ì´í„° ë¶„ì„\n\n"
            report_content += f"ì´ {len(self.analysis_results['stock_data'])}ê°œ íŒŒì¼ ë°œê²¬\n\n"
            
            for file_name, info in self.analysis_results['stock_data'].items():
                if 'error' not in info:
                    report_content += f"### {file_name}\n"
                    report_content += f"- í¬ê¸°: {info.get('file_size', 'N/A')}\n"
                    report_content += f"- í–‰ìˆ˜: {info.get('rows', 'N/A'):,}\n"
                    report_content += f"- ì»¬ëŸ¼: {info.get('columns', [])}\n"
                    if info.get('date_range') and isinstance(info['date_range'], dict):
                        report_content += f"- ê¸°ê°„: {info['date_range']['start']} ~ {info['date_range']['end']}\n"
                    report_content += "\n"
        
        # ê°ì„± ë°ì´í„° ë¶„ì„ ê²°ê³¼
        if 'sentiment_data' in self.analysis_results:
            report_content += f"\n## ğŸ­ ê°ì„± ë°ì´í„° ë¶„ì„\n\n"
            report_content += f"ì´ {len(self.analysis_results['sentiment_data'])}ê°œ íŒŒì¼ ë°œê²¬\n\n"
            
            for file_name, info in self.analysis_results['sentiment_data'].items():
                if 'error' not in info:
                    report_content += f"### {file_name}\n"
                    report_content += f"- í¬ê¸°: {info.get('file_size', 'N/A')}\n"
                    report_content += f"- í–‰ìˆ˜: {info.get('rows', 'N/A'):,}\n"
                    report_content += f"- ì»¬ëŸ¼: {info.get('columns', [])}\n"
                    if 'sentiment_columns' in info:
                        report_content += f"- ê°ì„± ì»¬ëŸ¼: {info['sentiment_columns']}\n"
                    report_content += "\n"
        
        # ì œí’ˆ ë°ì´í„° ë¶„ì„ ê²°ê³¼
        if 'product_data' in self.analysis_results:
            report_content += f"\n## ğŸ“± ì œí’ˆ ì¶œì‹œ ë°ì´í„° ë¶„ì„\n\n"
            report_content += f"ì´ {len(self.analysis_results['product_data'])}ê°œ íŒŒì¼ ë°œê²¬\n\n"
            
            for file_name, info in self.analysis_results['product_data'].items():
                if 'error' not in info:
                    report_content += f"### {file_name}\n"
                    report_content += f"- íƒ€ì…: {info.get('type', 'N/A')}\n"
                    if 'rows' in info:
                        report_content += f"- í–‰ìˆ˜: {info['rows']:,}\n"
                    if 'columns' in info:
                        report_content += f"- ì»¬ëŸ¼: {info['columns']}\n"
                    report_content += "\n"
        
        report_content += f"""
---

## ğŸ“Š ë‹¤ìŒ ë‹¨ê³„

1. **7ì¼ í‰ê·  í†µí•© ì‹œê°í™”**: 8ê°œ ì—°ë„ë³„ ì°¨íŠ¸ ìƒì„±
2. **LSTM ëª¨ë¸ ê°œì„ **: ì£¼ê°„ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ì „í™˜
3. **ì œí’ˆ ì¶œì‹œ ì„íŒ©íŠ¸ ë¶„ì„**: ì •ëŸ‰ì  ì˜í–¥ ì¸¡ì •

## ğŸ¯ ê¸°ëŒ€ ê²°ê³¼

- ë…¸ì´ì¦ˆ ê°ì†Œë¥¼ í†µí•œ ëª¨ë¸ ì„±ëŠ¥ ê°œì„  (RÂ² > 0.3 ëª©í‘œ)
- ì‹¤ìš©ì ì¸ ì£¼ê°„ ë‹¨ìœ„ ì˜ˆì¸¡ ì‹œìŠ¤í…œ êµ¬ì¶•
- ì œí’ˆ ì¶œì‹œì™€ ê°ì„±-ì£¼ê°€ ê°„ ìƒê´€ê´€ê³„ ì •ëŸ‰í™”
"""
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_path = f"{RESULTS_BASE}/reports/technical/data_structure_analysis.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"âœ… ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        
        # ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìš”ì•½ë„ ì €ì¥
        summary_path = f"{RESULTS_BASE}/reports/technical/data_quality_report.txt"
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write(f"ë°ì´í„° êµ¬ì¡° ë¶„ì„ ìš”ì•½ - {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"ì£¼ê°€ íŒŒì¼: {len(self.analysis_results.get('stock_data', {}))}ê°œ\n")
            f.write(f"ê°ì„± íŒŒì¼: {len(self.analysis_results.get('sentiment_data', {}))}ê°œ\n")
            f.write(f"ì œí’ˆ íŒŒì¼: {len(self.analysis_results.get('product_data', {}))}ê°œ\n")
            f.write(f"\në¶„ì„ ì™„ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
        
        print(f"âœ… ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥: {summary_path}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ - ë°ì´í„° êµ¬ì¡° í™•ì¸")
    print("=" * 60)
    print(f"í”„ë¡œì íŠ¸ ê¸°ë³¸ ê²½ë¡œ: {PROJECT_BASE}")
    print(f"ê²°ê³¼ë¬¼ ì €ì¥ ê²½ë¡œ: {RESULTS_BASE}")
    print("=" * 60)
    
    # 1. ê²°ê³¼ë¬¼ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±
    print("\n1ï¸âƒ£ ê²°ê³¼ë¬¼ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±")
    setup_directories()
    
    # 2. ë°ì´í„° êµ¬ì¡° ë¶„ì„ê¸° ì´ˆê¸°í™”
    print("\n2ï¸âƒ£ ë°ì´í„° êµ¬ì¡° ë¶„ì„ ì‹œì‘")
    analyzer = DataStructureAnalyzer(PROJECT_BASE)
    
    # 3. ê° ë°ì´í„° íƒ€ì…ë³„ ë¶„ì„ ìˆ˜í–‰
    analyzer.analyze_directory_structure()
    analyzer.analyze_stock_data()
    analyzer.analyze_sentiment_data()
    analyzer.analyze_product_data()
    
    # 4. ì‹œê°í™” ìƒì„±
    print("\n3ï¸âƒ£ ë°ì´í„° ê°œìš” ì‹œê°í™” ìƒì„±")
    analyzer.create_data_overview_visualization()
    
    # 5. ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥
    print("\n4ï¸âƒ£ ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸ ì €ì¥")
    analyzer.save_analysis_report()
    
    print("\n" + "=" * 60)
    print("âœ… ë°ì´í„° êµ¬ì¡° í™•ì¸ ë° ê²°ê³¼ë¬¼ í´ë” ì„¤ì • ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ë¬¼ í™•ì¸: {RESULTS_BASE}")
    print("ğŸ¯ ë‹¤ìŒ ë‹¨ê³„: 7.ì œí’ˆì¶œì‹œì¼ì •ì •ë¦¬.py ì‹¤í–‰")
    print("=" * 60)

if __name__ == "__main__":
    main()