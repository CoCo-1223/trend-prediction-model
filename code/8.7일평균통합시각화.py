"""
ë‰´ìŠ¤ ê°ì„± ë¶„ì„ ê¸°ë°˜ ì£¼ê°€ ì˜ˆì¸¡ ëª¨ë¸ - 7ì¼ í‰ê·  í†µí•© ì‹œê°í™”
ìƒì„±ì¼: 2025-06-08
íŒ€: í˜„ì¢…ë¯¼(íŒ€ì¥), ì‹ ì˜ˆì›(íŒ€ì›), ê¹€ì±„ì€(íŒ€ì›)

7ë²ˆì—ì„œ í™•ì¸ëœ ë°ì´í„° êµ¬ì¡°ë¥¼ ë°”íƒ•ìœ¼ë¡œ 7ì¼ í‰ê·  ê¸°ë°˜ í†µí•© ì‹œê°í™” ì‹œìŠ¤í…œ êµ¬ì¶•
- ê°ì„±ì ìˆ˜ + ì£¼ê°€ + ì œí’ˆì¶œì‹œì¼ í†µí•© ì°¨íŠ¸
- 8ê°œ ì—°ë„ë³„ ì°¨íŠ¸ (Apple 4ë…„ + Samsung 4ë…„)
- ë…¸ì´ì¦ˆ ê°ì†Œë¥¼ ìœ„í•œ 7ì¼ ì´ë™í‰ê·  ì ìš©
- ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ê°œë³„ ì°¨íŠ¸ ìƒì„± ë°©ì‹
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# ê²°ê³¼ë¬¼ ì €ì¥ ê²½ë¡œ ì„¤ì •
RESULTS_BASE = "/Users/jm/Desktop/ì¶©ë¶ëŒ€í•™êµ/ì¶©ëŒ€ 4í•™ë…„ 1í•™ê¸°/2. ë¹…ë°ì´í„°ì´í•´ì™€ë¶„ì„/íŒ€í”„ë¡œì íŠ¸/trend-prediction-model/results/2025-0608"
PROJECT_BASE = "/Users/jm/Desktop/ì¶©ë¶ëŒ€í•™êµ/ì¶©ëŒ€ 4í•™ë…„ 1í•™ê¸°/2. ë¹…ë°ì´í„°ì´í•´ì™€ë¶„ì„/íŒ€í”„ë¡œì íŠ¸/trend-prediction-model"

# í•œê¸€ í°íŠ¸ ì„¤ì • ë°©ì§€ - ì˜ì–´ ì œëª©ë§Œ ì‚¬ìš©
plt.rcParams['font.family'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 100
plt.rcParams['savefig.dpi'] = 300

def setup_directories():
    """ê²°ê³¼ë¬¼ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
    directories = [
        f"{RESULTS_BASE}/visualizations/weekly_analysis",
        f"{RESULTS_BASE}/data/processed",
        f"{RESULTS_BASE}/reports/technical"
    ]
    for dir_path in directories:
        os.makedirs(dir_path, exist_ok=True)
    print(f"âœ… ê²°ê³¼ë¬¼ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„± ì™„ë£Œ: {RESULTS_BASE}")

# ì‹¤í–‰ ì‹œì‘ ì‹œ ë””ë ‰í† ë¦¬ ìë™ ìƒì„±
setup_directories()

# 6ë²ˆì—ì„œ í™•ì¸ëœ ì‚¼ì„± ì£¼ê°€ íŒŒì¼ëª… ì—­ìˆœ ë§¤í•‘ ë¬¸ì œ í•´ê²°
STOCK_FILE_MAPPING = {
    'Samsung': {
        2021: 'Samsung_2024.csv',  # ì‹¤ì œ 2021 ë°ì´í„°ê°€ 2024 íŒŒì¼ì—
        2022: 'Samsung_2023.csv',  # ì‹¤ì œ 2022 ë°ì´í„°ê°€ 2023 íŒŒì¼ì—
        2023: 'Samsung_2022.csv',  # ì‹¤ì œ 2023 ë°ì´í„°ê°€ 2022 íŒŒì¼ì—
        2024: 'Samsung_2021.csv'   # ì‹¤ì œ 2024 ë°ì´í„°ê°€ 2021 íŒŒì¼ì—
    },
    'Apple': {  # Appleì€ ì •ìƒ
        2021: 'Apple Stock Price History_2021.csv',
        2022: 'Apple Stock Price History_2022.csv',
        2023: 'Apple Stock Price History_2023.csv',
        2024: 'Apple Stock Price History_2024.csv'
    }
}

# ì°¨íŠ¸ ì œëª© (ì˜ì–´ë¡œ í†µì¼)
CHART_TITLES = {
    'Apple': {
        2021: 'Apple 2021: 7-Day Average Sentiment vs Stock Price with Product Launches',
        2022: 'Apple 2022: 7-Day Average Sentiment vs Stock Price with Product Launches',
        2023: 'Apple 2023: 7-Day Average Sentiment vs Stock Price with Product Launches',
        2024: 'Apple 2024: 7-Day Average Sentiment vs Stock Price with Product Launches'
    },
    'Samsung': {
        2021: 'Samsung 2021: 7-Day Average Sentiment vs Stock Price with Product Launches',
        2022: 'Samsung 2022: 7-Day Average Sentiment vs Stock Price with Product Launches',
        2023: 'Samsung 2023: 7-Day Average Sentiment vs Stock Price with Product Launches',
        2024: 'Samsung 2024: 7-Day Average Sentiment vs Stock Price with Product Launches'
    }
}

class WeeklyTrendVisualizer:
    """7ì¼ í‰ê·  ê¸°ë°˜ ê°ì„±-ì£¼ê°€-ì œí’ˆì¶œì‹œ í†µí•© ì‹œê°í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.results_base = RESULTS_BASE
        self.project_base = PROJECT_BASE
        self.viz_path = f"{self.results_base}/visualizations/weekly_analysis"
        self.data_path = f"{self.results_base}/data/processed"
        self.stock_path = f"{self.project_base}/stock"
        self.data_folder = f"{self.project_base}/data/processed"  # processed í´ë”ë¡œ ë³€ê²½
        
        # 7ë²ˆì—ì„œ ìƒì„±ëœ ì œí’ˆ ì¶œì‹œ ë°ì´í„° ê²½ë¡œ
        self.product_data_path = f"{self.data_path}"
        self.combined_launches_file = f"{self.product_data_path}/combined_product_timeline.csv"
        
        # í†µí•© ë°ì´í„° ì €ì¥ìš©
        self.integrated_data = []
        
        print(f"ğŸ“Š WeeklyTrendVisualizer ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - ì‹œê°í™” ì €ì¥ ê²½ë¡œ: {self.viz_path}")
        print(f"   - ë°ì´í„° ì €ì¥ ê²½ë¡œ: {self.data_path}")
        
    def safe_load_sentiment_data(self, company: str, year: int):
        """ì•ˆì „í•œ ê°ì„± ë°ì´í„° ë¡œë”© (processed í´ë” ë‚´ íŒŒì¼ í™œìš©)"""
        try:
            # ê°ì„± ë°ì´í„° íŒŒì¼ íŒ¨í„´ (ì†Œë¬¸ì íšŒì‚¬ëª…)
            company_lower = company.lower()
            file_pattern = f"{company_lower}_sentiment_{year}.csv"
            file_path = f"{self.project_base}/data/processed/{file_pattern}"
            
            if not os.path.exists(file_path):
                print(f"âŒ {company} {year} ê°ì„± ë°ì´í„° íŒŒì¼ ì—†ìŒ: {file_path}")
                return pd.DataFrame()
            
            # UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ë¡œë”©
            df = pd.read_csv(file_path, encoding='utf-8')
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ (6ë²ˆì—ì„œ í™•ì¸ëœ êµ¬ì¡°)
            required_cols = ['ì¼ì', 'ê°ì •ì ìˆ˜']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                print(f"âš ï¸ {company} {year}: í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ {missing_cols}")
                return pd.DataFrame()
            
            # ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜
            df['ì¼ì'] = pd.to_datetime(df['ì¼ì'], errors='coerce')
            df = df.dropna(subset=['ì¼ì'])
            
            # ê°ì •ì ìˆ˜ ìˆ«ì ë³€í™˜
            df['ê°ì •ì ìˆ˜'] = pd.to_numeric(df['ê°ì •ì ìˆ˜'], errors='coerce')
            df = df.dropna(subset=['ê°ì •ì ìˆ˜'])
            
            print(f"âœ… {company} {year} ê°ì„± ë°ì´í„° ë¡œë”© ì„±ê³µ: {len(df)} ê±´")
            return df
            
        except Exception as e:
            print(f"âŒ {company} {year} ê°ì„± ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()
    
    def safe_load_stock_data(self, company: str, year: int):
        """ì•ˆì „í•œ ì£¼ê°€ ë°ì´í„° ë¡œë”© (6ë²ˆì—ì„œ ë°œê²¬ëœ íŒŒì¼ëª… ë§¤í•‘ ì ìš©)"""
        try:
            # íŒŒì¼ëª… ë§¤í•‘ ì ìš©
            filename = STOCK_FILE_MAPPING[company][year]
            file_path = f"{self.stock_path}/{filename}"
            
            if not os.path.exists(file_path):
                print(f"âŒ {company} {year} ì£¼ê°€ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {file_path}")
                return pd.DataFrame()
            
            # CSV ë¡œë”©
            df = pd.read_csv(file_path)
            
            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬ (Date ì»¬ëŸ¼ í™•ì¸)
            if 'Date' in df.columns:
                df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
                df = df.dropna(subset=['Date'])
                df = df.sort_values('Date')
            else:
                print(f"âš ï¸ {company} {year}: Date ì»¬ëŸ¼ ì—†ìŒ")
                return pd.DataFrame()
            
            # Close ê°€ê²© ìˆ«ì ë³€í™˜
            if 'Close' in df.columns:
                # ì‰¼í‘œ ì œê±° í›„ ìˆ«ì ë³€í™˜
                if df['Close'].dtype == 'object':
                    df['Close'] = df['Close'].astype(str).str.replace(',', '').str.replace('$', '')
                df['Close'] = pd.to_numeric(df['Close'], errors='coerce')
                df = df.dropna(subset=['Close'])
            else:
                print(f"âš ï¸ {company} {year}: Close ì»¬ëŸ¼ ì—†ìŒ")
                return pd.DataFrame()
            
            # í•´ë‹¹ ì—°ë„ ë°ì´í„°ë§Œ í•„í„°ë§
            df = df[df['Date'].dt.year == year]
            
            print(f"âœ… {company} {year} ì£¼ê°€ ë°ì´í„° ë¡œë”© ì„±ê³µ: {len(df)} ê±´")
            return df
            
        except Exception as e:
            print(f"âŒ {company} {year} ì£¼ê°€ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()
    
    def load_product_launches(self, company: str, year: int):
        """ì œí’ˆ ì¶œì‹œ ë°ì´í„° ë¡œë”© (7ë²ˆì—ì„œ ìƒì„±ëœ CSV í™œìš©)"""
        try:
            if not os.path.exists(self.combined_launches_file):
                print(f"âŒ ì œí’ˆ ì¶œì‹œ ë°ì´í„° íŒŒì¼ ì—†ìŒ: {self.combined_launches_file}")
                return pd.DataFrame()
            
            # í†µí•© ì œí’ˆ ì¶œì‹œ ë°ì´í„° ë¡œë”©
            df = pd.read_csv(self.combined_launches_file)
            df['Date'] = pd.to_datetime(df['Date'])
            
            # íšŒì‚¬ ë° ì—°ë„ í•„í„°ë§
            filtered = df[
                (df['Company'] == company) & 
                (df['Date'].dt.year == year)
            ]
            
            print(f"âœ… {company} {year} ì œí’ˆ ì¶œì‹œ ë°ì´í„°: {len(filtered)} ê±´")
            return filtered
            
        except Exception as e:
            print(f"âŒ {company} {year} ì œí’ˆ ì¶œì‹œ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()
    
    def calculate_7day_average(self, data, date_col, value_col):
        """7ì¼ ì´ë™í‰ê·  ê³„ì‚°"""
        try:
            # ë‚ ì§œ ìˆœì„œëŒ€ë¡œ ì •ë ¬
            data = data.sort_values(date_col).copy()
            
            # 7ì¼ ì´ë™í‰ê·  (ì¤‘ì•™ê°’ ê¸°ì¤€, ìµœì†Œ 3ì¼ ë°ì´í„°)
            data[f'{value_col}_7d_avg'] = data[value_col].rolling(
                window=7, 
                center=True,    # ì¤‘ì•™ê°’ ê¸°ì¤€
                min_periods=3   # ìµœì†Œ 3ì¼ ë°ì´í„°
            ).mean()
            
            return data
            
        except Exception as e:
            print(f"âŒ 7ì¼ í‰ê·  ê³„ì‚° ì˜¤ë¥˜: {str(e)}")
            return data
    
    def normalize_sentiment_volume(self, sentiment_df, company):
        """ê°ì„± ë°ì´í„° ë³¼ë¥¨ ì •ê·œí™” (ì‚¼ì„±ì€ ì• í”Œì˜ 8ë°° ë§ìŒ)"""
        try:
            if company == 'Samsung':
                # ì‚¼ì„±ì€ ë°ì´í„°ê°€ ë§ìœ¼ë¯€ë¡œ ì¼ë³„ í‰ê· ìœ¼ë¡œ ì§‘ê³„
                daily_avg = sentiment_df.groupby('ì¼ì')['ê°ì •ì ìˆ˜'].agg([
                    'mean', 'std', 'count'
                ]).reset_index()
                daily_avg.columns = ['Date', 'sentiment_score', 'sentiment_std', 'news_count']
            else:
                # ì• í”Œì€ ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ ì¼ë³„ í‰ê·  (ì´ë¯¸ ì ìŒ)
                daily_avg = sentiment_df.groupby('ì¼ì')['ê°ì •ì ìˆ˜'].agg([
                    'mean', 'std', 'count'
                ]).reset_index()
                daily_avg.columns = ['Date', 'sentiment_score', 'sentiment_std', 'news_count']
            
            # ê²°ì¸¡ê°’ ì²˜ë¦¬
            daily_avg['sentiment_std'] = daily_avg['sentiment_std'].fillna(0)
            
            return daily_avg
            
        except Exception as e:
            print(f"âŒ ê°ì„± ë³¼ë¥¨ ì •ê·œí™” ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()
    
    def create_integrated_chart(self, company: str, year: int):
        """í†µí•© ì°¨íŠ¸ ìƒì„± (ê°ì„± + ì£¼ê°€ + ì œí’ˆì¶œì‹œ)"""
        try:
            print(f"\nğŸ“Š {company} {year} í†µí•© ì°¨íŠ¸ ìƒì„± ì‹œì‘...")
            
            # 1. ë°ì´í„° ë¡œë”©
            sentiment_df = self.safe_load_sentiment_data(company, year)
            stock_df = self.safe_load_stock_data(company, year)
            launches_df = self.load_product_launches(company, year)
            
            if sentiment_df.empty or stock_df.empty:
                print(f"âš ï¸ {company} {year}: í•„ìˆ˜ ë°ì´í„° ì—†ìŒ, ì°¨íŠ¸ ìƒì„± ìŠ¤í‚µ")
                return False
            
            # 2. ê°ì„± ë°ì´í„° ì •ê·œí™” ë° ì¼ë³„ ì§‘ê³„
            daily_sentiment = self.normalize_sentiment_volume(sentiment_df, company)
            
            # 3. ì£¼ê°€ ë°ì´í„° ì¤€ë¹„
            stock_df_clean = stock_df[['Date', 'Close']].copy()
            stock_df_clean.columns = ['Date', 'stock_price']
            
            # 4. 7ì¼ í‰ê·  ê³„ì‚°
            daily_sentiment = self.calculate_7day_average(
                daily_sentiment, 'Date', 'sentiment_score'
            )
            stock_df_clean = self.calculate_7day_average(
                stock_df_clean, 'Date', 'stock_price'
            )
            
            # 5. ë°ì´í„° ë³‘í•© (ë‚ ì§œ ê¸°ì¤€)
            merged_data = pd.merge(
                daily_sentiment[['Date', 'sentiment_score_7d_avg', 'news_count']],
                stock_df_clean[['Date', 'stock_price_7d_avg']],
                on='Date',
                how='outer'
            )
            
            # ê²°ì¸¡ê°’ ì „ì§„ ì±„ì›€
            merged_data = merged_data.sort_values('Date')
            merged_data['sentiment_score_7d_avg'] = merged_data['sentiment_score_7d_avg'].fillna(method='ffill')
            merged_data['stock_price_7d_avg'] = merged_data['stock_price_7d_avg'].fillna(method='ffill')
            
            # 6. ì°¨íŠ¸ ìƒì„±
            fig, ax1 = plt.subplots(figsize=(16, 10))
            
            # ê°ì„± ì ìˆ˜ (7ì¼ í‰ê· )
            color1 = '#1f77b4'  # íŒŒë€ìƒ‰
            ax1.set_xlabel('Date', fontsize=12)
            ax1.set_ylabel('7-Day Average Sentiment Score', color=color1, fontsize=12)
            
            line1 = ax1.plot(merged_data['Date'], merged_data['sentiment_score_7d_avg'], 
                           color=color1, linewidth=2, label='Sentiment Score (7-day avg)', alpha=0.8)
            ax1.tick_params(axis='y', labelcolor=color1)
            ax1.grid(True, alpha=0.3)
            
            # ì£¼ê°€ (7ì¼ í‰ê· ) - ë‘ ë²ˆì§¸ Yì¶•
            ax2 = ax1.twinx()
            color2 = '#ff7f0e'  # ì£¼í™©ìƒ‰
            ax2.set_ylabel('7-Day Average Stock Price', color=color2, fontsize=12)
            
            line2 = ax2.plot(merged_data['Date'], merged_data['stock_price_7d_avg'], 
                           color=color2, linewidth=2, label='Stock Price (7-day avg)', alpha=0.8)
            ax2.tick_params(axis='y', labelcolor=color2)
            
            # 7. ì œí’ˆ ì¶œì‹œì¼ í‘œì‹œ
            launch_lines = []
            if not launches_df.empty:
                for idx, launch in launches_df.iterrows():
                    launch_date = launch['Date']
                    product_name = launch['Product']
                    
                    # ìˆ˜ì§ì„  ê·¸ë¦¬ê¸°
                    line = ax1.axvline(x=launch_date, color='red', linestyle='--', 
                                     alpha=0.7, linewidth=1.5)
                    launch_lines.append(line)
                    
                    # ì œí’ˆëª… ë¼ë²¨ (ìœ„ì¹˜ ì¡°ì •)
                    y_pos = ax1.get_ylim()[1] * (0.95 - (idx % 3) * 0.05)  # ê²¹ì¹¨ ë°©ì§€
                    ax1.text(launch_date, y_pos, product_name, 
                           rotation=45, fontsize=8, ha='left', va='bottom',
                           bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))
            
            # 8. ë²”ë¡€ ì„¤ì •
            lines1, labels1 = ax1.get_legend_handles_labels()
            lines2, labels2 = ax2.get_legend_handles_labels()
            
            # ì œí’ˆ ì¶œì‹œ ë²”ë¡€ ì¶”ê°€
            if launch_lines:
                lines1.extend([launch_lines[0]])
                labels1.extend(['Product Launch'])
            
            ax1.legend(lines1 + lines2, labels1 + labels2, 
                      loc='upper left', bbox_to_anchor=(0.02, 0.98))
            
            # 9. ì œëª© ë° ë ˆì´ì•„ì›ƒ ì„¤ì •
            chart_title = CHART_TITLES[company][year]
            plt.title(chart_title, fontsize=14, fontweight='bold', pad=20)
            
            # Xì¶• ë‚ ì§œ í˜•ì‹ ì„¤ì •
            ax1.tick_params(axis='x', rotation=45)
            plt.tight_layout()
            
            # 10. ì €ì¥
            filename = f"{company}_{year}_weekly_analysis.png"
            filepath = f"{self.viz_path}/{filename}"
            plt.savefig(filepath, dpi=300, bbox_inches='tight', 
                       facecolor='white', edgecolor='none')
            plt.close(fig)  # ë©”ëª¨ë¦¬ í•´ì œ
            
            print(f"âœ… {company} {year} ì°¨íŠ¸ ì €ì¥ ì™„ë£Œ: {filename}")
            
            # 11. í†µí•© ë°ì´í„° ì €ì¥ìš© ì¶”ê°€
            merged_data['Company'] = company
            merged_data['Year'] = year
            self.integrated_data.append(merged_data)
            
            return True
            
        except Exception as e:
            print(f"âŒ {company} {year} ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
            if 'fig' in locals():
                plt.close(fig)
            return False
    
    def save_integrated_data(self):
        """í†µí•© ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"""
        try:
            if not self.integrated_data:
                print("âš ï¸ ì €ì¥í•  í†µí•© ë°ì´í„° ì—†ìŒ")
                return
            
            # ëª¨ë“  ë°ì´í„° ê²°í•©
            combined_df = pd.concat(self.integrated_data, ignore_index=True)
            
            # CSV ì €ì¥
            output_file = f"{self.data_path}/weekly_sentiment_stock_data.csv"
            combined_df.to_csv(output_file, index=False, encoding='utf-8')
            
            print(f"âœ… í†µí•© ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_file}")
            print(f"   - ì´ ë°ì´í„° ê±´ìˆ˜: {len(combined_df)}")
            print(f"   - íšŒì‚¬ë³„ ë°ì´í„°: {combined_df.groupby('Company').size().to_dict()}")
            
        except Exception as e:
            print(f"âŒ í†µí•© ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {str(e)}")
    
    def generate_analysis_summary(self):
        """ì£¼ê°„ ë¶„ì„ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            summary_content = f"""# 7ì¼ í‰ê·  í†µí•© ì‹œê°í™” ë¶„ì„ ìš”ì•½

## ğŸ“Š ë¶„ì„ ê°œìš”
- **ë¶„ì„ ê¸°ê°„**: 2021-2024ë…„ (4ê°œë…„)
- **ëŒ€ìƒ ê¸°ì—…**: Apple, Samsung
- **ë¶„ì„ ë°©ë²•**: 7ì¼ ì´ë™í‰ê·  ê¸°ë°˜ ë…¸ì´ì¦ˆ ê°ì†Œ
- **í†µí•© ìš”ì†Œ**: ê°ì„±ì ìˆ˜ + ì£¼ê°€ + ì œí’ˆì¶œì‹œì¼

## ğŸ¯ ìƒì„±ëœ ì‹œê°í™”
- **ì´ ì°¨íŠ¸ ìˆ˜**: 8ê°œ (Apple 4ë…„ + Samsung 4ë…„)
- **ì €ì¥ ìœ„ì¹˜**: {self.viz_path}
- **ì°¨íŠ¸ í˜•ì‹**: PNG (300 DPI ê³ í’ˆì§ˆ)

## ğŸ“ˆ ë°ì´í„° ì²˜ë¦¬ ë°©ì‹

### ê°ì„± ë°ì´í„° ì²˜ë¦¬
- **ì‚¼ì„±**: ì¼ë³„ í‰ê·  ì§‘ê³„ í›„ 7ì¼ ì´ë™í‰ê·  (ë°ì´í„° ë³¼ë¥¨ 8ë°° ì°¨ì´ ê³ ë ¤)
- **ì• í”Œ**: ì›ë³¸ ì¼ë³„ ë°ì´í„°ì— 7ì¼ ì´ë™í‰ê·  ì ìš©
- **ë…¸ì´ì¦ˆ ê°ì†Œ**: ì¤‘ì•™ê°’ ê¸°ì¤€ 7ì¼ ì°½, ìµœì†Œ 3ì¼ ë°ì´í„° ìš”êµ¬

### ì£¼ê°€ ë°ì´í„° ì²˜ë¦¬
- **ì‚¼ì„± íŒŒì¼ëª… ì—­ìˆœ ë§¤í•‘**: 2021â†’2024íŒŒì¼, 2022â†’2023íŒŒì¼ ë“±
- **7ì¼ ì´ë™í‰ê· **: Close ê°€ê²© ê¸°ì¤€ ìŠ¤ë¬´ë”©
- **ê²°ì¸¡ê°’ ì²˜ë¦¬**: ì „ì§„ ì±„ì›€ ë°©ì‹

### ì œí’ˆ ì¶œì‹œ ë°ì´í„°
- **ì†ŒìŠ¤**: 7ë²ˆ ì½”ë“œì—ì„œ ìƒì„±ëœ í†µí•© CSV
- **í‘œì‹œ ë°©ì‹**: ë¹¨ê°„ ì ì„  + ì œí’ˆëª… ë¼ë²¨
- **ê²¹ì¹¨ ë°©ì§€**: Yì¶• ìœ„ì¹˜ ìë™ ì¡°ì •

## ğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­

### ê¸°ìˆ ì  ê°œì„ ì 
1. **ë…¸ì´ì¦ˆ ê°ì†Œ íš¨ê³¼**: 7ì¼ í‰ê· ìœ¼ë¡œ ì¼ë³„ ë³€ë™ì„± í¬ê²Œ ê°ì†Œ
2. **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: ê°œë³„ ì°¨íŠ¸ ìƒì„±ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë¶€ì¡± ë°©ì§€
3. **ë°ì´í„° í’ˆì§ˆ**: ì‚¼ì„± ì£¼ê°€ íŒŒì¼ëª… ì—­ìˆœ ë¬¸ì œ í•´ê²°

### ì‹œê°ì  ê°œì„ ì 
1. **ì´ì¤‘ Yì¶•**: ê°ì„±ì ìˆ˜ì™€ ì£¼ê°€ ìŠ¤ì¼€ì¼ ì°¨ì´ í•´ê²°
2. **ì œí’ˆ ì¶œì‹œ í‘œì‹œ**: ëª…í™•í•œ ì‹œê°ì  êµ¬ë¶„ìœ¼ë¡œ ì´ë²¤íŠ¸ ì¶”ì  ê°€ëŠ¥
3. **ì˜ì–´ ì œëª©**: í•œê¸€ í°íŠ¸ ë¬¸ì œ ì™„ì „ í•´ê²°

## ğŸ“ ê²°ê³¼ë¬¼ ìš”ì•½
- **ì‹œê°í™”**: {self.viz_path}/*.png (8ê°œ íŒŒì¼)
- **ì²˜ë¦¬ëœ ë°ì´í„°**: {self.data_path}/weekly_sentiment_stock_data.csv
- **ë¶„ì„ ë¦¬í¬íŠ¸**: {RESULTS_BASE}/reports/technical/weekly_analysis_summary.md

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„
1. **LSTM ëª¨ë¸ ê°œì„ **: ì£¼ê°„ í‰ê·  ë°ì´í„°ë¡œ ëª¨ë¸ ì¬í•™ìŠµ
2. **ì„íŒ©íŠ¸ ë¶„ì„**: ì œí’ˆ ì¶œì‹œê°€ ê°ì„±-ì£¼ê°€ì— ë¯¸ì¹˜ëŠ” ì •ëŸ‰ì  ì˜í–¥ ë¶„ì„
3. **íŒ¨í„´ ë°œê²¬**: ì—°ë„ë³„ íŠ¹ì§•ì  íŠ¸ë Œë“œ ì‹¬í™” ë¶„ì„

---
**ìƒì„±ì¼**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ì²˜ë¦¬ ì™„ë£Œ ì‹œê°„**: {datetime.now()}
"""
            
            # ë¦¬í¬íŠ¸ ì €ì¥
            report_file = f"{RESULTS_BASE}/reports/technical/weekly_analysis_summary.md"
            with open(report_file, 'w', encoding='utf-8') as f:
                f.write(summary_content)
            
            print(f"âœ… ë¶„ì„ ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥ ì™„ë£Œ: {report_file}")
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}")
    
    def generate_all_charts(self):
        """8ê°œ ì°¨íŠ¸ ìˆœì°¨ ìƒì„± (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )"""
        print(f"\nğŸš€ 7ì¼ í‰ê·  í†µí•© ì‹œê°í™” ì‹œì‘...")
        print(f"ğŸ“… ëŒ€ìƒ ê¸°ê°„: 2021-2024ë…„")
        print(f"ğŸ¢ ëŒ€ìƒ ê¸°ì—…: Apple, Samsung")
        print(f"ğŸ“Š ìƒì„± ì˜ˆì • ì°¨íŠ¸: 8ê°œ\n")
        
        companies = ['Apple', 'Samsung']
        years = [2021, 2022, 2023, 2024]
        
        success_count = 0
        total_count = len(companies) * len(years)
        
        for company in companies:
            for year in years:
                print(f"{'='*50}")
                success = self.create_integrated_chart(company, year)
                if success:
                    success_count += 1
                print(f"ì§„í–‰ë¥ : {success_count}/{total_count} ì™„ë£Œ")
        
        # í†µí•© ë°ì´í„° ì €ì¥
        self.save_integrated_data()
        
        # ë¶„ì„ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
        self.generate_analysis_summary()
        
        print(f"\nğŸ‰ 7ì¼ í‰ê·  í†µí•© ì‹œê°í™” ì™„ë£Œ!")
        print(f"âœ… ì„±ê³µ: {success_count}/{total_count} ì°¨íŠ¸")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {self.viz_path}")
        print(f"ğŸ“Š í†µí•© ë°ì´í„°: {self.data_path}/weekly_sentiment_stock_data.csv")
        
        return success_count == total_count

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ“Š ë‰´ìŠ¤ ê°ì„± ë¶„ì„ - 7ì¼ í‰ê·  í†µí•© ì‹œê°í™” ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    # ì‹œê°í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    visualizer = WeeklyTrendVisualizer()
    
    # ëª¨ë“  ì°¨íŠ¸ ìƒì„±
    success = visualizer.generate_all_charts()
    
    if success:
        print("\nğŸŠ ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“ˆ ë‹¤ìŒ ë‹¨ê³„: 9ë²ˆ ì½”ë“œ(LSTM ë°ì´í„° ì „ì²˜ë¦¬)ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    else:
        print("\nâš ï¸ ì¼ë¶€ ì°¨íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()