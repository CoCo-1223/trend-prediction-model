"""
ë¹…ì¹´ì¸ì¦ˆ ë‰´ìŠ¤ ë°ì´í„° ê¸°ë°˜ PyTorch LSTM ê°ì„± íŠ¸ë Œë“œ ì˜ˆì¸¡ ëª¨ë¸
í”„ë¡œì íŠ¸: ë‰´ìŠ¤ ë°ì´í„° ê¸°ë°˜ ê°ì„± íŠ¸ë Œë“œ ì˜ˆì¸¡ ëª¨ë¸

ì£¼ìš” ê¸°ëŠ¥:
1. ë¹…ì¹´ì¸ì¦ˆ ë‰´ìŠ¤ ë°ì´í„° ì „ì²˜ë¦¬
2. FinBERT ê¸°ë°˜ ê°ì„± ë¶„ì„  
3. PyTorch LSTM ëª¨ë¸ì„ í™œìš©í•œ ì‹œê³„ì—´ ê°ì„± íŠ¸ë Œë“œ ì˜ˆì¸¡
4. ì‚¼ì„±ì „ì, ì• í”Œ ê°ì„± íŠ¸ë Œë“œ ì‹œê°í™” ë° ë¹„êµ ë¶„ì„
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# PyTorch ë° NLP ë¼ì´ë¸ŒëŸ¬ë¦¬
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from transformers import pipeline
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
import re
from tqdm.auto import tqdm

# ì‹œê°í™” ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'  # í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['axes.unicode_minus'] = False

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

class TimeSeriesDataset(Dataset):
    """ì‹œê³„ì—´ ë°ì´í„°ì…‹ í´ë˜ìŠ¤"""
    def __init__(self, X, y):
        self.X = torch.FloatTensor(X)
        self.y = torch.FloatTensor(y)
    
    def __len__(self):
        return len(self.X)
    
    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

class LSTMModel(nn.Module):
    """PyTorch LSTM ëª¨ë¸ í´ë˜ìŠ¤"""
    def __init__(self, input_size, hidden_size=64, num_layers=2, dropout=0.3):
        super(LSTMModel, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTM ë ˆì´ì–´
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout,
            batch_first=True,
            bidirectional=True
        )
        
        # ë“œë¡­ì•„ì›ƒ
        self.dropout = nn.Dropout(dropout)
        
        # ì™„ì „ì—°ê²°ì¸µ
        self.fc1 = nn.Linear(hidden_size * 2, 32)  # bidirectionalì´ë¯€ë¡œ *2
        self.fc2 = nn.Linear(32, 16)
        self.fc3 = nn.Linear(16, 1)
        
        # í™œì„±í™” í•¨ìˆ˜
        self.relu = nn.ReLU()
        
    def forward(self, x):
        # LSTM ìˆœì „íŒŒ
        lstm_out, _ = self.lstm(x)
        
        # ë§ˆì§€ë§‰ ì‹œê°„ ìŠ¤í…ì˜ ì¶œë ¥ ì‚¬ìš©
        lstm_out = lstm_out[:, -1, :]
        
        # ì™„ì „ì—°ê²°ì¸µ ìˆœì „íŒŒ
        out = self.dropout(lstm_out)
        out = self.relu(self.fc1(out))
        out = self.dropout(out)
        out = self.relu(self.fc2(out))
        out = self.fc3(out)
        
        return out

class BigKindsPyTorchLSTMAnalyzer:
    def __init__(self, data_path):
        """
        ë¹…ì¹´ì¸ì¦ˆ ë°ì´í„° ê¸°ë°˜ PyTorch LSTM ê°ì„± ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            data_path (str): ë¹…ì¹´ì¸ì¦ˆ ë°ì´í„° íŒŒì¼ë“¤ì´ ìˆëŠ” ê²½ë¡œ
        """
        self.data_path = data_path
        self.file_paths = [
            f"{data_path}/NewsResult_20210101-20211231.xlsx",
            f"{data_path}/NewsResult_20220101-20221231.xlsx", 
            f"{data_path}/NewsResult_20230101-20231231.xlsx",
            f"{data_path}/NewsResult_20240101-20241231.xlsx"
        ]
        
        # ê°ì„± ë¶„ì„ ëª¨ë¸ ì´ˆê¸°í™” (KR-FinBERT-SC)
        print("ğŸ¤– FinBERT ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.sentiment_analyzer = pipeline(
            "sentiment-analysis",
            model="snunlp/KR-FinBert-SC",
            tokenizer="snunlp/KR-FinBert-SC",
            device=0 if torch.cuda.is_available() else -1,
            top_k=None
        )
        
        # ë°ì´í„° ì €ì¥ìš©
        self.raw_data = None
        self.processed_data = None
        self.sentiment_data = None
        self.lstm_models = {}
        self.scalers = {}
        
    def load_data(self):
        """ë¹…ì¹´ì¸ì¦ˆ ì—‘ì…€ íŒŒì¼ë“¤ì„ ë¶ˆëŸ¬ì™€ì„œ í†µí•©"""
        print("ğŸ“Š ë¹…ì¹´ì¸ì¦ˆ ë‰´ìŠ¤ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        all_data = []
        
        for file_path in self.file_paths:
            try:
                print(f"   - {file_path.split('/')[-1]} ë¡œë”© ì¤‘...")
                df = pd.read_excel(file_path)
                
                # ì»¬ëŸ¼ëª… í™•ì¸ ë° ì¶œë ¥
                print(f"     ì»¬ëŸ¼: {list(df.columns)}")
                
                # í•„ìš”í•œ ì»¬ëŸ¼ ì°¾ê¸° (ìœ ì—°í•œ ì»¬ëŸ¼ëª… ë§¤ì¹­)
                date_col = None
                title_col = None
                keyword_col = None
                content_col = None
                media_col = None
                
                for col in df.columns:
                    col_lower = col.lower()
                    if any(keyword in col_lower for keyword in ['ì¼ì', 'ë‚ ì§œ', 'date']):
                        date_col = col
                    elif any(keyword in col_lower for keyword in ['ì œëª©', 'title']):
                        title_col = col
                    elif any(keyword in col_lower for keyword in ['í‚¤ì›Œë“œ', 'keyword']):
                        keyword_col = col
                    elif any(keyword in col_lower for keyword in ['ë³¸ë¬¸', 'content', 'ë‚´ìš©']):
                        content_col = col
                    elif any(keyword in col_lower for keyword in ['ì–¸ë¡ ì‚¬', 'ë§¤ì²´', 'media']):
                        media_col = col
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
                if not date_col or not title_col:
                    print(f"     âš ï¸ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: ì¼ì({date_col}), ì œëª©({title_col})")
                    continue
                
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
                selected_cols = [date_col, title_col]
                if keyword_col:
                    selected_cols.append(keyword_col)
                if content_col:
                    selected_cols.append(content_col)
                if media_col:
                    selected_cols.append(media_col)
                
                df_selected = df[selected_cols].copy()
                
                # ì»¬ëŸ¼ëª… í‘œì¤€í™”
                df_selected = df_selected.rename(columns={
                    date_col: 'ì¼ì',
                    title_col: 'ì œëª©',
                    keyword_col: 'í‚¤ì›Œë“œ' if keyword_col else None,
                    content_col: 'ë³¸ë¬¸' if content_col else None,
                    media_col: 'ì–¸ë¡ ì‚¬' if media_col else None
                })
                
                # None ì»¬ëŸ¼ ì œê±°
                df_selected = df_selected.loc[:, df_selected.columns.notna()]
                
                all_data.append(df_selected)
                print(f"     âœ“ {len(df_selected)}ê±´ ë¡œë”© ì™„ë£Œ")
                
            except Exception as e:
                print(f"     âœ— íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
                continue
        
        if all_data:
            self.raw_data = pd.concat(all_data, ignore_index=True)
            print(f"ğŸ“ˆ ì´ {len(self.raw_data)}ê±´ì˜ ë‰´ìŠ¤ ë°ì´í„° ë¡œë”© ì™„ë£Œ\n")
            
            # ë°ì´í„° ê¸°ë³¸ ì •ë³´ ì¶œë ¥
            print("ğŸ“‹ ë°ì´í„° ê¸°ë³¸ ì •ë³´:")
            print(f"   - ì»¬ëŸ¼: {list(self.raw_data.columns)}")
            if 'ì¼ì' in self.raw_data.columns:
                print(f"   - ê¸°ê°„: {self.raw_data['ì¼ì'].min()} ~ {self.raw_data['ì¼ì'].max()}")
            
            return True
        else:
            print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
            return False
    
    def preprocess_data(self):
        """ë°ì´í„° ì „ì²˜ë¦¬"""
        print("ğŸ”§ ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
        
        if self.raw_data is None:
            print("âŒ ë°ì´í„°ê°€ ë¡œë”©ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        df = self.raw_data.copy()
        
        # 1. ë‚ ì§œ ì²˜ë¦¬
        print("   - ë‚ ì§œ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        try:
            if df['ì¼ì'].dtype == 'object':
                # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
                df['ì¼ì'] = pd.to_datetime(df['ì¼ì'], errors='coerce', infer_datetime_format=True)
            elif df['ì¼ì'].dtype in ['int64', 'float64']:
                # ìˆ«ì í˜•íƒœì¸ ê²½ìš° (ì˜ˆ: 20210101)
                df['ì¼ì'] = pd.to_datetime(df['ì¼ì'].astype(str), format='%Y%m%d', errors='coerce')
        except Exception as e:
            print(f"     ë‚ ì§œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return False
        
        # 2. ê²°ì¸¡ê°’ ì²˜ë¦¬
        print("   - ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...")
        original_count = len(df)
        df = df.dropna(subset=['ì¼ì', 'ì œëª©'])  # í•„ìˆ˜ ì»¬ëŸ¼ì˜ ê²°ì¸¡ê°’ ì œê±°
        print(f"     ê²°ì¸¡ê°’ ì œê±°: {original_count} â†’ {len(df)}ê±´")
        
        # ë¹ˆ ì»¬ëŸ¼ ì±„ìš°ê¸°
        for col in ['í‚¤ì›Œë“œ', 'ë³¸ë¬¸', 'ì–¸ë¡ ì‚¬']:
            if col in df.columns:
                df[col] = df[col].fillna('')
        
        # 3. í…ìŠ¤íŠ¸ ê²°í•© (ì œëª© + í‚¤ì›Œë“œ + ë³¸ë¬¸)
        print("   - í…ìŠ¤íŠ¸ ë°ì´í„° ê²°í•© ì¤‘...")
        def combine_text(row):
            text_parts = []
            if pd.notna(row.get('ì œëª©', '')) and str(row['ì œëª©']).strip():
                text_parts.append(str(row['ì œëª©']).strip())
            if 'í‚¤ì›Œë“œ' in row and pd.notna(row.get('í‚¤ì›Œë“œ', '')) and str(row['í‚¤ì›Œë“œ']).strip():
                text_parts.append(f"í‚¤ì›Œë“œ: {str(row['í‚¤ì›Œë“œ']).strip()}")
            if 'ë³¸ë¬¸' in row and pd.notna(row.get('ë³¸ë¬¸', '')) and str(row['ë³¸ë¬¸']).strip():
                # ë³¸ë¬¸ì´ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
                content = str(row['ë³¸ë¬¸']).strip()[:500]
                text_parts.append(content)
            return ' '.join(text_parts)
        
        df['combined_text'] = df.apply(combine_text, axis=1)
        
        # 4. ê¸°ì—… ë¶„ë¥˜ (ì‚¼ì„±/ì• í”Œ)
        print("   - ê¸°ì—… ë¶„ë¥˜ ì¤‘...")
        def classify_company(text):
            text_lower = str(text).lower()
            samsung_keywords = ['ì‚¼ì„±ì „ì', 'ì‚¼ì„±', 'samsung', 'ê°¤ëŸ­ì‹œ', 'galaxy', 'sdi', 'ë°˜ë„ì²´', 'dram', 'nand']
            apple_keywords = ['ì• í”Œ', 'apple', 'ì•„ì´í°', 'iphone', 'ì•„ì´íŒ¨ë“œ', 'ipad', 'ë§¥ë¶', 'macbook', 'ios', 'macos']
            
            samsung_count = sum(1 for keyword in samsung_keywords if keyword in text_lower)
            apple_count = sum(1 for keyword in apple_keywords if keyword in text_lower)
            
            if samsung_count > apple_count and samsung_count > 0:
                return 'samsung'
            elif apple_count > samsung_count and apple_count > 0:
                return 'apple'
            elif samsung_count > 0 and apple_count > 0:
                return 'both'
            else:
                return 'none'
        
        df['company'] = df['combined_text'].apply(classify_company)
        
        # 5. í…ìŠ¤íŠ¸ ì •ì œ
        print("   - í…ìŠ¤íŠ¸ ì •ì œ ì¤‘...")
        def clean_text(text):
            if pd.isna(text):
                return ""
            
            text = str(text)
            # HTML íƒœê·¸ ì œê±°
            text = re.sub(r'<[^>]+>', '', text)
            # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±, ì¼ë¶€ íŠ¹ìˆ˜ë¬¸ìë§Œ ìœ ì§€)
            text = re.sub(r'[^\w\sê°€-í£.,!?:%-]', ' ', text)
            # ì—°ì†ëœ ê³µë°± ì œê±°
            text = re.sub(r'\s+', ' ', text)
            return text.strip()
        
        df['cleaned_text'] = df['combined_text'].apply(clean_text)
        
        # 6. ë¹ˆ í…ìŠ¤íŠ¸ ë° ê´€ë ¨ ì—†ëŠ” ê¸°ì‚¬ ì œê±°
        original_count = len(df)
        df = df[df['cleaned_text'].str.len() > 10]  # 10ì ì´ìƒì˜ í…ìŠ¤íŠ¸ë§Œ ìœ ì§€
        df = df[df['company'].isin(['samsung', 'apple'])]  # ê´€ë ¨ ê¸°ì—…ë§Œ ìœ ì§€
        print(f"     í•„í„°ë§: {original_count} â†’ {len(df)}ê±´")
        
        self.processed_data = df.reset_index(drop=True)
        
        samsung_count = len(df[df['company'] == 'samsung'])
        apple_count = len(df[df['company'] == 'apple'])
        
        print(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(self.processed_data)}ê±´")
        print(f"   - ì‚¼ì„±: {samsung_count}ê±´")
        print(f"   - ì• í”Œ: {apple_count}ê±´\n")
        
        return True
    
    def analyze_sentiment(self, batch_size=16):
        """FinBERT ê¸°ë°˜ ê°ì„± ë¶„ì„"""
        print("ğŸ¯ FinBERT ê°ì„± ë¶„ì„ ì‹œì‘...")
        
        if self.processed_data is None:
            print("âŒ ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        df = self.processed_data.copy()
        
        def sentiment_to_score(sentiment_result):
            """ê°ì„± ë¶„ì„ ê²°ê³¼ë¥¼ 1-5 ì ìˆ˜ë¡œ ë³€í™˜"""
            try:
                if isinstance(sentiment_result, list):
                    # í™•ë¥  ë”•ì…”ë„ˆë¦¬ ìƒì„±
                    prob_dict = {item['label']: item['score'] for item in sentiment_result}
                    
                    # ìµœê³  í™•ë¥ ì˜ ê°ì„± ì„ íƒ
                    best_label = max(prob_dict, key=prob_dict.get)
                    best_score = prob_dict[best_label]
                    
                    # 3ê°€ì§€ ê°ì„±ì— ëŒ€í•œ í™•ë¥ 
                    pos_prob = prob_dict.get('positive', 0)
                    neg_prob = prob_dict.get('negative', 0)
                    neu_prob = prob_dict.get('neutral', 0)
                    
                    # 1-5 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜ (ê°€ì¤‘í‰ê·  ë°©ì‹)
                    score = 1.0 * neg_prob + 3.0 * neu_prob + 5.0 * pos_prob
                    
                else:
                    # ë‹¨ì¼ ê²°ê³¼ì¸ ê²½ìš°
                    label = sentiment_result['label']
                    confidence = sentiment_result['score']
                    
                    if label == 'positive':
                        score = 3.0 + 2.0 * confidence
                    elif label == 'negative':
                        score = 3.0 - 2.0 * confidence
                    else:  # neutral
                        score = 3.0
                    
                    best_label = label
                
                return max(1.0, min(5.0, score)), best_label
                
            except Exception as e:
                print(f"ê°ì„± ì ìˆ˜ ë³€í™˜ ì˜¤ë¥˜: {e}")
                return 3.0, 'neutral'
        
        # ë°°ì¹˜ë³„ë¡œ ê°ì„± ë¶„ì„ ìˆ˜í–‰
        sentiment_scores = []
        sentiment_labels = []
        
        texts = df['cleaned_text'].tolist()
        
        print(f"   - ì´ {len(texts)}ê°œ í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ (ë°°ì¹˜ í¬ê¸°: {batch_size})...")
        
        for i in tqdm(range(0, len(texts), batch_size), desc="ê°ì„± ë¶„ì„"):
            batch_texts = texts[i:i + batch_size]
            
            try:
                # ê° í…ìŠ¤íŠ¸ë¥¼ 512ìë¡œ ì œí•œ
                batch_texts = [text[:512] for text in batch_texts]
                
                # ê°ì„± ë¶„ì„ ìˆ˜í–‰
                results = self.sentiment_analyzer(batch_texts, truncation=True, max_length=512)
                
                for result in results:
                    score, label = sentiment_to_score(result)
                    sentiment_scores.append(score)
                    sentiment_labels.append(label)
                    
            except Exception as e:
                print(f"     ë°°ì¹˜ {i//batch_size + 1} ë¶„ì„ ì‹¤íŒ¨: {e}")
                # ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” ì¤‘ë¦½ìœ¼ë¡œ ì²˜ë¦¬
                for _ in range(len(batch_texts)):
                    sentiment_scores.append(3.0)
                    sentiment_labels.append('neutral')
        
        df['sentiment_score'] = sentiment_scores
        df['sentiment_label'] = sentiment_labels
        
        self.sentiment_data = df
        
        print(f"âœ… ê°ì„± ë¶„ì„ ì™„ë£Œ")
        print(f"   - ê¸ì •: {len(df[df['sentiment_label']=='positive'])}ê±´")
        print(f"   - ì¤‘ë¦½: {len(df[df['sentiment_label']=='neutral'])}ê±´")
        print(f"   - ë¶€ì •: {len(df[df['sentiment_label']=='negative'])}ê±´")
        print(f"   - í‰ê·  ê°ì„± ì ìˆ˜: {df['sentiment_score'].mean():.2f}\n")
        
        return True
    
    def prepare_time_series_data(self, company='samsung'):
        """ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„"""
        print(f"ğŸ“ˆ {company.upper()} ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„ ì¤‘...")
        
        if self.sentiment_data is None:
            print("âŒ ê°ì„± ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # í•´ë‹¹ ê¸°ì—… ë°ì´í„° í•„í„°ë§
        company_data = self.sentiment_data[self.sentiment_data['company'] == company].copy()
        
        if len(company_data) == 0:
            print(f"âŒ {company} ê´€ë ¨ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì¼ë³„ ì§‘ê³„
        daily_data = company_data.groupby('ì¼ì').agg({
            'sentiment_score': ['mean', 'std', 'count'],
            'sentiment_label': lambda x: (x == 'positive').sum() / len(x)  # ê¸ì • ë¹„ìœ¨
        }).reset_index()
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        daily_data.columns = ['date', 'sentiment_mean', 'sentiment_std', 'news_count', 'positive_ratio']
        daily_data['sentiment_std'] = daily_data['sentiment_std'].fillna(0)
        
        # ë‚ ì§œìˆœ ì •ë ¬
        daily_data = daily_data.sort_values('date').reset_index(drop=True)
        
        # ì´ë™í‰ê·  ê³„ì‚°
        daily_data['sentiment_ma7'] = daily_data['sentiment_mean'].rolling(window=7, min_periods=1).mean()
        daily_data['sentiment_ma30'] = daily_data['sentiment_mean'].rolling(window=30, min_periods=1).mean()
        daily_data['news_count_ma7'] = daily_data['news_count'].rolling(window=7, min_periods=1).mean()
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        daily_data = daily_data.fillna(method='ffill').fillna(method='bfill')
        
        print(f"âœ… ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {len(daily_data)}ì¼ê°„ì˜ ë°ì´í„°")
        print(f"   - ê¸°ê°„: {daily_data['date'].min()} ~ {daily_data['date'].max()}")
        print(f"   - ì¼í‰ê·  ê¸°ì‚¬ ìˆ˜: {daily_data['news_count'].mean():.1f}ê±´\n")
        
        return daily_data
    
    def create_sequences(self, data, features, target, sequence_length=30):
        """LSTMìš© ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±"""
        X, y = [], []
        
        for i in range(sequence_length, len(data)):
            X.append(data[features].iloc[i-sequence_length:i].values)
            y.append(data[target].iloc[i])
        
        return np.array(X), np.array(y)
    
    def train_pytorch_lstm(self, company='samsung', sequence_length=30, epochs=100, learning_rate=0.001):
        """PyTorch LSTM ëª¨ë¸ í›ˆë ¨"""
        print(f"ğŸ¤– {company.upper()} PyTorch LSTM ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
        
        # ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„
        time_series_data = self.prepare_time_series_data(company)
        if time_series_data is None:
            return None
        
        # íŠ¹ì„± ì„ íƒ
        features = ['sentiment_mean', 'sentiment_std', 'news_count', 'positive_ratio', 
                   'sentiment_ma7', 'news_count_ma7']
        target = 'sentiment_mean'
        
        # ë°ì´í„° ì •ê·œí™”
        scaler_X = MinMaxScaler()
        scaler_y = MinMaxScaler()
        
        X_scaled = scaler_X.fit_transform(time_series_data[features])
        y_scaled = scaler_y.fit_transform(time_series_data[[target]])
        
        # ì •ê·œí™”ëœ ë°ì´í„°ë¡œ DataFrame ìƒì„±
        scaled_data = pd.DataFrame(X_scaled, columns=features)
        scaled_data[target] = y_scaled.flatten()
        
        # LSTM ì‹œí€€ìŠ¤ ìƒì„±
        X, y = self.create_sequences(scaled_data, features, target, sequence_length)
        
        if len(X) == 0:
            print("âŒ ì¶©ë¶„í•œ ì‹œí€€ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
        train_size = int(len(X) * 0.8)
        X_train, X_test = X[:train_size], X[train_size:]
        y_train, y_test = y[:train_size], y[train_size:]
        
        print(f"   - í›ˆë ¨ ë°ì´í„°: {len(X_train)}ê°œ ì‹œí€€ìŠ¤")
        print(f"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ ì‹œí€€ìŠ¤")
        
        # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±
        train_dataset = TimeSeriesDataset(X_train, y_train)
        test_dataset = TimeSeriesDataset(X_test, y_test)
        
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        model = LSTMModel(input_size=len(features)).to(device)
        criterion = nn.MSELoss()
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5)
        
        # í›ˆë ¨ ê¸°ë¡
        train_losses = []
        val_losses = []
        best_val_loss = float('inf')
        patience_counter = 0
        
        print("   - í›ˆë ¨ ì‹œì‘...")
        
        for epoch in range(epochs):
            # í›ˆë ¨ ë‹¨ê³„
            model.train()
            train_loss = 0
            for X_batch, y_batch in train_loader:
                X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                
                optimizer.zero_grad()
                outputs = model(X_batch)
                loss = criterion(outputs.squeeze(), y_batch)
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
            
            # ê²€ì¦ ë‹¨ê³„
            model.eval()
            val_loss = 0
            with torch.no_grad():
                for X_batch, y_batch in test_loader:
                    X_batch, y_batch = X_batch.to(device), y_batch.to(device)
                    outputs = model(X_batch)
                    val_loss += criterion(outputs.squeeze(), y_batch).item()
            
            train_loss /= len(train_loader)
            val_loss /= len(test_loader)
            
            train_losses.append(train_loss)
            val_losses.append(val_loss)
            
            # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬
            scheduler.step(val_loss)
            
            # ì¡°ê¸° ì¢…ë£Œ
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                # ìµœìƒì˜ ëª¨ë¸ ì €ì¥
                best_model_state = model.state_dict().copy()
            else:
                patience_counter += 1
                if patience_counter >= 15:
                    print(f"     ì¡°ê¸° ì¢…ë£Œ (ì—í¬í¬ {epoch+1})")
                    break
            
            if (epoch + 1) % 20 == 0:
                print(f"     ì—í¬í¬ [{epoch+1}/{epochs}] - í›ˆë ¨ ì†ì‹¤: {train_loss:.4f}, ê²€ì¦ ì†ì‹¤: {val_loss:.4f}")
        
        # ìµœìƒì˜ ëª¨ë¸ ë¡œë“œ
        model.load_state_dict(best_model_state)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
        model.eval()
        predictions = []
        actuals = []
        
        with torch.no_grad():
            for X_batch, y_batch in test_loader:
                X_batch = X_batch.to(device)
                outputs = model(X_batch)
                predictions.extend(outputs.cpu().numpy())
                actuals.extend(y_batch.numpy())
        
        predictions = np.array(predictions).flatten()
        actuals = np.array(actuals).flatten()
        
        # ì •ê·œí™” í•´ì œ
        predictions_original = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()
        actuals_original = scaler_y.inverse_transform(actuals.reshape(-1, 1)).flatten()
        
        # ì„±ëŠ¥ í‰ê°€
        mse = mean_squared_error(actuals_original, predictions_original)
        mae = mean_absolute_error(actuals_original, predictions_original)
        r2 = r2_score(actuals_original, predictions_original)
        
        print(f"âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
        print(f"   - MSE: {mse:.4f}")
        print(f"   - MAE: {mae:.4f}")
        print(f"   - RÂ²: {r2:.4f}\n")
        
        # ëª¨ë¸ ì •ë³´ ì €ì¥
        self.lstm_models[company] = {
            'model': model,
            'scaler_X': scaler_X,
            'scaler_y': scaler_y,
            'sequence_length': sequence_length,
            'features': features,
            'train_losses': train_losses,
            'val_losses': val_losses,
            'time_series_data': time_series_data,
            'test_results': {
                'predictions': predictions_original,
                'actuals': actuals_original,
                'mse': mse,
                'mae': mae,
                'r2': r2
            }
        }
        
        return self.lstm_models[company]
    
    def predict_future_sentiment(self, company='samsung', days=30):
        """ë¯¸ë˜ ê°ì„± ì ìˆ˜ ì˜ˆì¸¡"""
        print(f"ğŸ”® {company.upper()} í–¥í›„ {days}ì¼ ê°ì„± ì˜ˆì¸¡...")
        
        if company not in self.lstm_models:
            print(f"âŒ {company} ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        model_info = self.lstm_models[company]
        model = model_info['model']
        scaler_X = model_info['scaler_X']
        scaler_y = model_info['scaler_y']
        sequence_length = model_info['sequence_length']
        features = model_info['features']
        time_series_data = model_info['time_series_data']
        
        # ë§ˆì§€ë§‰ ì‹œí€€ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        last_sequence = scaler_X.transform(time_series_data[features].tail(sequence_length))
        
        model.eval()
        predictions = []
        current_sequence = torch.FloatTensor(last_sequence).unsqueeze(0).to(device)
        
        with torch.no_grad():
            for _ in range(days):
                # ì˜ˆì¸¡ ìˆ˜í–‰
                pred_scaled = model(current_sequence)
                pred_value = pred_scaled.cpu().numpy()[0, 0]
                
                # ì •ê·œí™” í•´ì œí•˜ì—¬ ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€í™˜
                pred_original = scaler_y.inverse_transform([[pred_value]])[0, 0]
                predictions.append(pred_original)
                
                # ì‹œí€€ìŠ¤ ì—…ë°ì´íŠ¸ (ê°„ë‹¨í•œ ë°©ë²•: ì˜ˆì¸¡ê°’ì„ ì²« ë²ˆì§¸ íŠ¹ì„±ìœ¼ë¡œ ì‚¬ìš©)
                new_features = current_sequence[0, -1].clone()
                new_features[0] = pred_scaled[0, 0]  # sentiment_mean ì—…ë°ì´íŠ¸
                
                # ì‹œí€€ìŠ¤ ë¡¤ë§
                current_sequence = torch.cat([
                    current_sequence[:, 1:, :],
                    new_features.unsqueeze(0).unsqueeze(0)
                ], dim=1)
        
        # ë¯¸ë˜ ë‚ ì§œ ìƒì„±
        last_date = time_series_data['date'].max()
        future_dates = pd.date_range(start=last_date + timedelta(days=1), periods=days)
        
        future_df = pd.DataFrame({
            'date': future_dates,
            'predicted_sentiment': predictions
        })
        
        print(f"âœ… ë¯¸ë˜ ì˜ˆì¸¡ ì™„ë£Œ")
        print(f"   - ì˜ˆì¸¡ ê¸°ê°„: {future_dates[0]} ~ {future_dates[-1]}")
        print(f"   - í‰ê·  ì˜ˆì¸¡ ê°ì„± ì ìˆ˜: {np.mean(predictions):.2f}\n")
        
        return future_df
    
    def visualize_results(self, company='samsung'):
        """ê²°ê³¼ ì‹œê°í™”"""
        print(f"ğŸ“Š {company.upper()} ë¶„ì„ ê²°ê³¼ ì‹œê°í™”...")
        
        if company not in self.lstm_models:
            print(f"âŒ {company} ëª¨ë¸ì´ í›ˆë ¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        model_info = self.lstm_models[company]
        time_series_data = model_info['time_series_data']
        test_results = model_info['test_results']
        train_losses = model_info['train_losses']
        val_losses = model_info['val_losses']
        
        # 1. ì „ì²´ ê°ì„± íŠ¸ë Œë“œ ì‹œê°í™”
        plt.figure(figsize=(20, 15))
        
        # ì„œë¸Œí”Œë¡¯ 1: ì¼ë³„ ê°ì„± ì ìˆ˜ ë° ì´ë™í‰ê· 
        plt.subplot(3, 3, 1)
        plt.plot(time_series_data['date'], time_series_data['sentiment_mean'], 
                alpha=0.4, color='blue', label='ì¼ë³„ ê°ì„± ì ìˆ˜', linewidth=1)
        plt.plot(time_series_data['date'], time_series_data['sentiment_ma7'], 
                color='orange', label='7ì¼ ì´ë™í‰ê· ', linewidth=2)
        plt.plot(time_series_data['date'], time_series_data['sentiment_ma30'], 
                color='red', label='30ì¼ ì´ë™í‰ê· ', linewidth=2)
        plt.title(f'{company.upper()} ì¼ë³„ ê°ì„± ì ìˆ˜ íŠ¸ë Œë“œ', fontsize=14)
        plt.ylabel('ê°ì„± ì ìˆ˜')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        
        # ì„œë¸Œí”Œë¡¯ 2: ì¼ë³„ ê¸°ì‚¬ ìˆ˜
        plt.subplot(3, 3, 2)
        plt.bar(time_series_data['date'], time_series_data['news_count'], 
               alpha=0.6, color='green', label='ì¼ë³„ ê¸°ì‚¬ ìˆ˜')
        plt.plot(time_series_data['date'], time_series_data['news_count_ma7'], 
                color='darkgreen', label='7ì¼ ì´ë™í‰ê· ', linewidth=2)
        plt.title(f'{company.upper()} ì¼ë³„ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜', fontsize=14)
        plt.ylabel('ê¸°ì‚¬ ìˆ˜')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        
        # ì„œë¸Œí”Œë¡¯ 3: ê¸ì • ë¹„ìœ¨
        plt.subplot(3, 3, 3)
        plt.plot(time_series_data['date'], time_series_data['positive_ratio'], 
                color='purple', marker='o', markersize=3, label='ê¸ì • ë¹„ìœ¨', linewidth=1.5)
        plt.title(f'{company.upper()} ì¼ë³„ ê¸ì • ë‰´ìŠ¤ ë¹„ìœ¨', fontsize=14)
        plt.ylabel('ê¸ì • ë¹„ìœ¨')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        
        # ì„œë¸Œí”Œë¡¯ 4: LSTM ëª¨ë¸ í•™ìŠµ ê³¼ì •
        plt.subplot(3, 3, 4)
        plt.plot(train_losses, label='Training Loss', linewidth=2)
        plt.plot(val_losses, label='Validation Loss', linewidth=2)
        plt.title('PyTorch LSTM ëª¨ë¸ í•™ìŠµ ê³¼ì •', fontsize=14)
        plt.ylabel('Loss')
        plt.xlabel('Epochs')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # ì„œë¸Œí”Œë¡¯ 5: ì˜ˆì¸¡ vs ì‹¤ì œ (í…ŒìŠ¤íŠ¸ ë°ì´í„°)
        plt.subplot(3, 3, 5)
        test_dates = time_series_data['date'].iloc[-len(test_results['actuals']):]
        plt.plot(test_dates, test_results['actuals'], 'b-', label='ì‹¤ì œ ê°’', alpha=0.8, linewidth=2)
        plt.plot(test_dates, test_results['predictions'], 'r--', label='ì˜ˆì¸¡ ê°’', alpha=0.8, linewidth=2)
        plt.title('LSTM ì˜ˆì¸¡ ì„±ëŠ¥ (í…ŒìŠ¤íŠ¸ ë°ì´í„°)', fontsize=14)
        plt.ylabel('ê°ì„± ì ìˆ˜')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        
        # ì„œë¸Œí”Œë¡¯ 6: ì‚°ì ë„ (ì˜ˆì¸¡ vs ì‹¤ì œ)
        plt.subplot(3, 3, 6)
        plt.scatter(test_results['actuals'], test_results['predictions'], alpha=0.7, s=50)
        min_val = min(test_results['actuals'].min(), test_results['predictions'].min())
        max_val = max(test_results['actuals'].max(), test_results['predictions'].max())
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2)
        plt.xlabel('ì‹¤ì œ ê°’')
        plt.ylabel('ì˜ˆì¸¡ ê°’')
        plt.title(f'ì˜ˆì¸¡ ì •í™•ë„ (RÂ² = {test_results["r2"]:.3f})', fontsize=14)
        plt.grid(True, alpha=0.3)
        
        # ì„œë¸Œí”Œë¡¯ 7: ê°ì„± ì ìˆ˜ ë¶„í¬
        plt.subplot(3, 3, 7)
        company_sentiment = self.sentiment_data[self.sentiment_data['company'] == company]['sentiment_score']
        plt.hist(company_sentiment, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        plt.axvline(company_sentiment.mean(), color='red', linestyle='--', linewidth=2, label=f'í‰ê· : {company_sentiment.mean():.2f}')
        plt.title(f'{company.upper()} ê°ì„± ì ìˆ˜ ë¶„í¬', fontsize=14)
        plt.xlabel('ê°ì„± ì ìˆ˜')
        plt.ylabel('ë¹ˆë„')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # ì„œë¸Œí”Œë¡¯ 8: ì›”ë³„ ê°ì„± íŠ¸ë Œë“œ
        plt.subplot(3, 3, 8)
        monthly_data = time_series_data.copy()
        monthly_data['year_month'] = monthly_data['date'].dt.to_period('M')
        monthly_avg = monthly_data.groupby('year_month')['sentiment_mean'].mean()
        
        plt.plot(range(len(monthly_avg)), monthly_avg.values, marker='o', linewidth=2, markersize=6)
        plt.title(f'{company.upper()} ì›”ë³„ í‰ê·  ê°ì„± ì ìˆ˜', fontsize=14)
        plt.xlabel('ì›”')
        plt.ylabel('í‰ê·  ê°ì„± ì ìˆ˜')
        plt.xticks(range(0, len(monthly_avg), max(1, len(monthly_avg)//6)), 
                  [str(month) for i, month in enumerate(monthly_avg.index) if i % max(1, len(monthly_avg)//6) == 0], 
                  rotation=45)
        plt.grid(True, alpha=0.3)
        
        # ì„œë¸Œí”Œë¡¯ 9: ê°ì„± ë³€ë™ì„± (í‘œì¤€í¸ì°¨)
        plt.subplot(3, 3, 9)
        plt.plot(time_series_data['date'], time_series_data['sentiment_std'], 
                color='orange', marker='o', markersize=3, label='ê°ì„± ë³€ë™ì„±', linewidth=1.5)
        plt.title(f'{company.upper()} ì¼ë³„ ê°ì„± ë³€ë™ì„±', fontsize=14)
        plt.ylabel('í‘œì¤€í¸ì°¨')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        
        plt.tight_layout()
        plt.savefig(f'{company}_pytorch_lstm_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 2. ë¯¸ë˜ ì˜ˆì¸¡ ì‹œê°í™”
        future_pred = self.predict_future_sentiment(company, days=30)
        
        if future_pred is not None:
            plt.figure(figsize=(16, 10))
            
            # ìƒë‹¨: ê³¼ê±° + ë¯¸ë˜ ì˜ˆì¸¡
            plt.subplot(2, 1, 1)
            recent_data = time_series_data.tail(90)  # ìµœê·¼ 90ì¼
            plt.plot(recent_data['date'], recent_data['sentiment_mean'], 
                    'b-', label='ê³¼ê±° ì‹¤ì œ ê°ì„± ì ìˆ˜', linewidth=2.5, alpha=0.8)
            plt.plot(recent_data['date'], recent_data['sentiment_ma7'], 
                    'orange', label='ê³¼ê±° 7ì¼ ì´ë™í‰ê· ', linewidth=2, alpha=0.8)
            
            # ë¯¸ë˜ ì˜ˆì¸¡
            plt.plot(future_pred['date'], future_pred['predicted_sentiment'], 
                    'r--', label='ë¯¸ë˜ ì˜ˆì¸¡ ê°ì„± ì ìˆ˜', linewidth=3, marker='o', markersize=4)
            
            # í˜„ì¬ ì‹œì  í‘œì‹œ
            plt.axvline(x=time_series_data['date'].max(), color='green', 
                       linestyle='-', alpha=0.8, linewidth=2, label='í˜„ì¬')
            
            # ì‹ ë¢°êµ¬ê°„ (ë‹¨ìˆœíˆ Â±0.2 ë²”ìœ„ë¡œ í‘œì‹œ)
            plt.fill_between(future_pred['date'], 
                           future_pred['predicted_sentiment'] - 0.2,
                           future_pred['predicted_sentiment'] + 0.2,
                           alpha=0.2, color='red', label='ì˜ˆì¸¡ ì‹ ë¢°êµ¬ê°„')
            
            plt.title(f'{company.upper()} ê°ì„± ì ìˆ˜ ì˜ˆì¸¡ (ê³¼ê±° 90ì¼ + ë¯¸ë˜ 30ì¼)', fontsize=16)
            plt.xlabel('ë‚ ì§œ')
            plt.ylabel('ê°ì„± ì ìˆ˜')
            plt.legend()
            plt.grid(True, alpha=0.3)
            plt.xticks(rotation=45)
            
            # í•˜ë‹¨: ì˜ˆì¸¡ íŠ¸ë Œë“œ ë¶„ì„
            plt.subplot(2, 1, 2)
            
            # ì˜ˆì¸¡ê°’ì˜ ë³€í™”ìœ¨ ê³„ì‚°
            pred_values = future_pred['predicted_sentiment'].values
            trend_changes = np.diff(pred_values)
            
            colors = ['red' if x < 0 else 'green' for x in trend_changes]
            plt.bar(range(len(trend_changes)), trend_changes, color=colors, alpha=0.7)
            plt.title('ì¼ë³„ ê°ì„± ì ìˆ˜ ë³€í™” ì˜ˆì¸¡', fontsize=14)
            plt.xlabel('ì˜ˆì¸¡ ì¼ìˆ˜')
            plt.ylabel('ê°ì„± ì ìˆ˜ ë³€í™”ëŸ‰')
            plt.axhline(y=0, color='black', linestyle='-', alpha=0.5)
            plt.grid(True, alpha=0.3)
            
            plt.tight_layout()
            plt.savefig(f'{company}_future_prediction.png', dpi=300, bbox_inches='tight')
            plt.show()
        
        print(f"âœ… {company.upper()} ì‹œê°í™” ì™„ë£Œ\n")
    
    def generate_comprehensive_report(self):
        """ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("ğŸ“ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        
        report = []
        report.append("=" * 80)
        report.append("ğŸ“Š ë¹…ì¹´ì¸ì¦ˆ ë‰´ìŠ¤ ë°ì´í„° ê¸°ë°˜ PyTorch LSTM ê°ì„± íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸")
        report.append("=" * 80)
        report.append(f"ë¶„ì„ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
        report.append("")
        
        # 1. ë°ì´í„° ê°œìš”
        if self.sentiment_data is not None:
            report.append("ğŸ“ˆ ë°ì´í„° ê°œìš”")
            report.append("-" * 50)
            report.append(f"ì´ ë‰´ìŠ¤ ê¸°ì‚¬ ìˆ˜: {len(self.sentiment_data):,}ê±´")
            report.append(f"ë¶„ì„ ê¸°ê°„: {self.sentiment_data['ì¼ì'].min().strftime('%Y-%m-%d')} ~ {self.sentiment_data['ì¼ì'].max().strftime('%Y-%m-%d')}")
            
            samsung_count = len(self.sentiment_data[self.sentiment_data['company'] == 'samsung'])
            apple_count = len(self.sentiment_data[self.sentiment_data['company'] == 'apple'])
            
            report.append(f"ì‚¼ì„± ê´€ë ¨ ë‰´ìŠ¤: {samsung_count:,}ê±´ ({samsung_count/len(self.sentiment_data)*100:.1f}%)")
            report.append(f"ì• í”Œ ê´€ë ¨ ë‰´ìŠ¤: {apple_count:,}ê±´ ({apple_count/len(self.sentiment_data)*100:.1f}%)")
            report.append("")
            
            # 2. ê°ì„± ë¶„ì„ ê²°ê³¼
            sentiment_dist = self.sentiment_data['sentiment_label'].value_counts()
            report.append("ğŸ¯ ì „ì²´ ê°ì„± ë¶„ì„ ê²°ê³¼")
            report.append("-" * 50)
            for sentiment, count in sentiment_dist.items():
                percentage = (count / len(self.sentiment_data)) * 100
                report.append(f"{sentiment.upper()}: {count:,}ê±´ ({percentage:.1f}%)")
            report.append(f"í‰ê·  ê°ì„± ì ìˆ˜: {self.sentiment_data['sentiment_score'].mean():.3f}/5.0")
            report.append(f"ê°ì„± ì ìˆ˜ í‘œì¤€í¸ì°¨: {self.sentiment_data['sentiment_score'].std():.3f}")
            report.append("")
            
            # 3. ê¸°ì—…ë³„ ê°ì„± ë¶„ì„
            report.append("ğŸ¢ ê¸°ì—…ë³„ ê°ì„± ë¶„ì„ ë¹„êµ")
            report.append("-" * 50)
            
            for company in ['samsung', 'apple']:
                company_data = self.sentiment_data[self.sentiment_data['company'] == company]
                if len(company_data) > 0:
                    avg_sentiment = company_data['sentiment_score'].mean()
                    std_sentiment = company_data['sentiment_score'].std()
                    positive_ratio = (company_data['sentiment_label'] == 'positive').mean()
                    negative_ratio = (company_data['sentiment_label'] == 'negative').mean()
                    
                    report.append(f"{company.upper()}:")
                    report.append(f"  - í‰ê·  ê°ì„± ì ìˆ˜: {avg_sentiment:.3f}/5.0")
                    report.append(f"  - ê°ì„± ì ìˆ˜ í‘œì¤€í¸ì°¨: {std_sentiment:.3f}")
                    report.append(f"  - ê¸ì • ë‰´ìŠ¤ ë¹„ìœ¨: {positive_ratio:.1%}")
                    report.append(f"  - ë¶€ì • ë‰´ìŠ¤ ë¹„ìœ¨: {negative_ratio:.1%}")
                    report.append("")
        
        # 4. LSTM ëª¨ë¸ ì„±ëŠ¥
        report.append("ğŸ¤– PyTorch LSTM ëª¨ë¸ ì„±ëŠ¥ ë¶„ì„")
        report.append("-" * 50)
        
        for company in ['samsung', 'apple']:
            if company in self.lstm_models:
                model_info = self.lstm_models[company]
                test_results = model_info['test_results']
                
                report.append(f"{company.upper()} LSTM ëª¨ë¸:")
                report.append(f"  - MSE (í‰ê· ì œê³±ì˜¤ì°¨): {test_results['mse']:.4f}")
                report.append(f"  - MAE (í‰ê· ì ˆëŒ€ì˜¤ì°¨): {test_results['mae']:.4f}")
                report.append(f"  - RÂ² (ê²°ì •ê³„ìˆ˜): {test_results['r2']:.4f}")
                
                # ì„±ëŠ¥ í•´ì„
                if test_results['r2'] > 0.8:
                    performance = "ë§¤ìš° ìš°ìˆ˜"
                elif test_results['r2'] > 0.6:
                    performance = "ìš°ìˆ˜"
                elif test_results['r2'] > 0.4:
                    performance = "ì–‘í˜¸"
                elif test_results['r2'] > 0.2:
                    performance = "ë³´í†µ"
                else:
                    performance = "ê°œì„  í•„ìš”"
                
                report.append(f"  - ëª¨ë¸ ì„±ëŠ¥ í‰ê°€: {performance}")
                
                # ì‹œê³„ì—´ ë°ì´í„° ì •ë³´
                time_series_data = model_info['time_series_data']
                report.append(f"  - ì‹œê³„ì—´ ë°ì´í„° í¬ì¸íŠ¸: {len(time_series_data)}ì¼")
                report.append(f"  - ì¼í‰ê·  ê¸°ì‚¬ ìˆ˜: {time_series_data['news_count'].mean():.1f}ê±´")
                report.append("")
        
        # 5. ì‹œê°„ì  íŠ¸ë Œë“œ ë¶„ì„
        if self.sentiment_data is not None:
            report.append("ğŸ“… ì‹œê°„ì  íŠ¸ë Œë“œ ë¶„ì„")
            report.append("-" * 50)
            
            # ì—°ë„ë³„ íŠ¸ë Œë“œ
            yearly_sentiment = self.sentiment_data.groupby(self.sentiment_data['ì¼ì'].dt.year)['sentiment_score'].mean()
            report.append("ì—°ë„ë³„ í‰ê·  ê°ì„± ì ìˆ˜:")
            for year, score in yearly_sentiment.items():
                report.append(f"  - {year}ë…„: {score:.3f}")
            
            # ì „ì²´ íŠ¸ë Œë“œ ë°©í–¥
            if len(yearly_sentiment) > 1:
                trend_direction = "ìƒìŠ¹" if yearly_sentiment.iloc[-1] > yearly_sentiment.iloc[0] else "í•˜ë½"
                trend_magnitude = abs(yearly_sentiment.iloc[-1] - yearly_sentiment.iloc[0])
                report.append(f"ì „ì²´ íŠ¸ë Œë“œ: {trend_direction} ({trend_magnitude:.3f}ì  ë³€í™”)")
            report.append("")
            
            # ì›”ë³„ ë³€ë™ì„± ë¶„ì„
            monthly_sentiment = self.sentiment_data.groupby(self.sentiment_data['ì¼ì'].dt.to_period('M'))['sentiment_score'].agg(['mean', 'std'])
            volatility = monthly_sentiment['std'].mean()
            report.append(f"ì›”ë³„ ê°ì„± ë³€ë™ì„± (í‰ê· ): {volatility:.3f}")
            report.append("")
        
        # 6. ë¯¸ë˜ ì˜ˆì¸¡ ê²°ê³¼
        report.append("ğŸ”® ë¯¸ë˜ ê°ì„± íŠ¸ë Œë“œ ì˜ˆì¸¡")
        report.append("-" * 50)
        
        for company in self.lstm_models.keys():
            future_pred = self.predict_future_sentiment(company, days=30)
            if future_pred is not None:
                current_sentiment = self.lstm_models[company]['time_series_data']['sentiment_mean'].iloc[-1]
                future_avg = future_pred['predicted_sentiment'].mean()
                trend_change = future_avg - current_sentiment
                
                report.append(f"{company.upper()} í–¥í›„ 30ì¼ ì˜ˆì¸¡:")
                report.append(f"  - í˜„ì¬ ê°ì„± ì ìˆ˜: {current_sentiment:.3f}")
                report.append(f"  - ì˜ˆì¸¡ í‰ê·  ê°ì„± ì ìˆ˜: {future_avg:.3f}")
                report.append(f"  - ì˜ˆìƒ ë³€í™”: {'+' if trend_change > 0 else ''}{trend_change:.3f}")
                
                if abs(trend_change) > 0.1:
                    direction = "ê°œì„ " if trend_change > 0 else "ì•…í™”"
                    report.append(f"  - íŠ¸ë Œë“œ ì „ë§: {direction} ì˜ˆìƒ")
                else:
                    report.append(f"  - íŠ¸ë Œë“œ ì „ë§: ì•ˆì •ì  ìœ ì§€ ì˜ˆìƒ")
                report.append("")
        
        # 7. ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ë° ê¶Œê³ ì‚¬í•­
        report.append("ğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ë° ê¶Œê³ ì‚¬í•­")
        report.append("-" * 50)
        
        insights = []
        
        # ê¸°ì—…ë³„ ê°ì„± ë¹„êµ
        if len(self.lstm_models) >= 2:
            samsung_sentiment = self.sentiment_data[self.sentiment_data['company'] == 'samsung']['sentiment_score'].mean()
            apple_sentiment = self.sentiment_data[self.sentiment_data['company'] == 'apple']['sentiment_score'].mean()
            
            if samsung_sentiment > apple_sentiment:
                insights.append(f"ì‚¼ì„±ì „ìì˜ ë‰´ìŠ¤ ê°ì„±ì´ ì• í”Œë³´ë‹¤ {samsung_sentiment - apple_sentiment:.3f}ì  ë†’ìŒ")
            else:
                insights.append(f"ì• í”Œì˜ ë‰´ìŠ¤ ê°ì„±ì´ ì‚¼ì„±ì „ìë³´ë‹¤ {apple_sentiment - samsung_sentiment:.3f}ì  ë†’ìŒ")
        
        # ëª¨ë¸ ì„±ëŠ¥ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        reliable_models = []
        for company, model_info in self.lstm_models.items():
            if model_info['test_results']['r2'] > 0.5:
                reliable_models.append(company)
        
        if reliable_models:
            insights.append(f"{', '.join([c.upper() for c in reliable_models])} ëª¨ë¸ì˜ ì˜ˆì¸¡ ì‹ ë¢°ë„ê°€ ë†’ìŒ (RÂ² > 0.5)")
        
        # ë³€ë™ì„± ë¶„ì„
        if self.sentiment_data is not None:
            high_volatility_threshold = 0.5
            for company in ['samsung', 'apple']:
                company_data = self.sentiment_data[self.sentiment_data['company'] == company]
                if len(company_data) > 0:
                    volatility = company_data['sentiment_score'].std()
                    if volatility > high_volatility_threshold:
                        insights.append(f"{company.upper()}ì˜ ê°ì„± ë³€ë™ì„±ì´ ë†’ìŒ (Ïƒ={volatility:.3f})")
        
        for i, insight in enumerate(insights, 1):
            report.append(f"{i}. {insight}")
        
        report.append("")
        report.append("ğŸ“‹ í™œìš© ë°©ì•ˆ")
        report.append("-" * 50)
        applications = [
            "ì‹¤ì‹œê°„ ê¸°ì—… ì´ë¯¸ì§€ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ êµ¬ì¶•",
            "ì œí’ˆ ì¶œì‹œ íƒ€ì´ë° ìµœì í™”ë¥¼ ìœ„í•œ ê°ì„± ë¶„ì„",
            "ê²½ìŸì‚¬ ëŒ€ë¹„ ë¸Œëœë“œ í¬ì§€ì…”ë‹ ë¶„ì„",
            "ìœ„ê¸° ê´€ë¦¬ë¥¼ ìœ„í•œ ë¶€ì • ê°ì„± ì¡°ê¸° ê°ì§€",
            "ë§ˆì¼€íŒ… ìº í˜ì¸ íš¨ê³¼ ì¸¡ì • ë° ìµœì í™”",
            "íˆ¬ì ì˜ì‚¬ê²°ì • ë³´ì¡° ì§€í‘œë¡œ í™œìš©",
            "ì–¸ë¡  ëŒ€ì‘ ì „ëµ ìˆ˜ë¦½ì„ ìœ„í•œ ê°ì„± íŠ¸ë Œë“œ ë¶„ì„"
        ]
        
        for i, app in enumerate(applications, 1):
            report.append(f"{i}. {app}")
        
        report.append("")
        report.append("ğŸ”§ ëª¨ë¸ ê°œì„  ë°©ì•ˆ")
        report.append("-" * 50)
        improvements = [
            "ì™¸ë¶€ ë°ì´í„° í†µí•© (ì£¼ê°€, ê²½ì œì§€í‘œ, ì†Œì…œë¯¸ë””ì–´)",
            "ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ ì ìš©ìœ¼ë¡œ ì¤‘ìš” ì‹œì  ê°€ì¤‘ì¹˜ ë¶€ì—¬",
            "ì•™ìƒë¸” ëª¨ë¸ êµ¬ì„± (LSTM + GRU + Transformer)",
            "í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ë² ì´ì§€ì•ˆ ìµœì í™”)",
            "ì‹¤ì‹œê°„ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•",
            "ì„¤ëª… ê°€ëŠ¥í•œ AI ê¸°ë²• ì ìš© (SHAP, LIME)",
            "ë‹¤ì¤‘ ì‹œê°„ í•´ìƒë„ ì˜ˆì¸¡ (ì¼/ì£¼/ì›”ë³„)"
        ]
        
        for i, improvement in enumerate(improvements, 1):
            report.append(f"{i}. {improvement}")
        
        report.append("")
        report.append("=" * 80)
        report.append("ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ")
        report.append("=" * 80)
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_text = "\n".join(report)
        with open("PyTorch_LSTM_Sentiment_Analysis_Report.txt", "w", encoding="utf-8") as f:
            f.write(report_text)
        
        print("âœ… ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: PyTorch_LSTM_Sentiment_Analysis_Report.txt")
        return report_text
    
    def run_complete_analysis(self):
        """ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        print("ğŸš€ ë¹…ì¹´ì¸ì¦ˆ ë‰´ìŠ¤ ë°ì´í„° PyTorch LSTM ê°ì„± ë¶„ì„ ì‹œì‘!")
        print("=" * 80)
        
        start_time = datetime.now()
        
        try:
            # 1. ë°ì´í„° ë¡œë”©
            print("1ï¸âƒ£ ë°ì´í„° ë¡œë”© ë‹¨ê³„")
            if not self.load_data():
                print("âŒ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨ë¡œ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return False
            
            # 2. ë°ì´í„° ì „ì²˜ë¦¬
            print("2ï¸âƒ£ ë°ì´í„° ì „ì²˜ë¦¬ ë‹¨ê³„")
            if not self.preprocess_data():
                print("âŒ ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤íŒ¨ë¡œ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return False
            
            # 3. ê°ì„± ë¶„ì„
            print("3ï¸âƒ£ ê°ì„± ë¶„ì„ ë‹¨ê³„")
            if not self.analyze_sentiment():
                print("âŒ ê°ì„± ë¶„ì„ ì‹¤íŒ¨ë¡œ ë¶„ì„ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return False
            
            # 4. LSTM ëª¨ë¸ í›ˆë ¨
            print("4ï¸âƒ£ LSTM ëª¨ë¸ í›ˆë ¨ ë‹¨ê³„")
            trained_models = []
            
            for company in ['samsung', 'apple']:
                company_data = self.sentiment_data[self.sentiment_data['company'] == company]
                if len(company_data) > 100:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ë§Œ í›ˆë ¨
                    print(f"   {company.upper()} ëª¨ë¸ í›ˆë ¨ ì¤‘...")
                    model_info = self.train_pytorch_lstm(company)
                    if model_info:
                        trained_models.append(company)
                else:
                    print(f"   âš ï¸ {company.upper()} ë°ì´í„° ë¶€ì¡± (í•„ìš”: 100ê°œ, í˜„ì¬: {len(company_data)}ê°œ)")
            
            if not trained_models:
                print("âŒ í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            # 5. ê²°ê³¼ ì‹œê°í™”
            print("5ï¸âƒ£ ê²°ê³¼ ì‹œê°í™” ë‹¨ê³„")
            for company in trained_models:
                print(f"   {company.upper()} ì‹œê°í™” ìƒì„± ì¤‘...")
                self.visualize_results(company)
            
            # 6. ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
            print("6ï¸âƒ£ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ë‹¨ê³„")
            self.generate_comprehensive_report()
            
            # ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            end_time = datetime.now()
            execution_time = end_time - start_time
            
            print("\nğŸ‰ ì „ì²´ ë¶„ì„ ì™„ë£Œ!")
            print("=" * 80)
            print(f"â±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {execution_time}")
            print(f"ğŸ“Š í›ˆë ¨ëœ ëª¨ë¸: {', '.join([c.upper() for c in trained_models])}")
            print(f"ğŸ“ˆ ìƒì„±ëœ íŒŒì¼:")
            print(f"   - ì‹œê°í™”: {', '.join([f'{c}_pytorch_lstm_analysis.png' for c in trained_models])}")
            print(f"   - ì˜ˆì¸¡ ì°¨íŠ¸: {', '.join([f'{c}_future_prediction.png' for c in trained_models])}")
            print(f"   - ì¢…í•© ë¦¬í¬íŠ¸: PyTorch_LSTM_Sentiment_Analysis_Report.txt")
            
            return True
            
        except Exception as e:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def interactive_analysis(self):
        """ëŒ€í™”í˜• ë¶„ì„ ëª¨ë“œ"""
        print("ğŸ” ëŒ€í™”í˜• ë¶„ì„ ëª¨ë“œ")
        print("=" * 50)
        
        while True:
            print("\nì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´:")
            print("1. ê°ì„± ë°ì´í„° ìš”ì•½ ë³´ê¸°")
            print("2. íŠ¹ì • ê¸°ì—… ì‹œê°í™”")
            print("3. ë¯¸ë˜ ì˜ˆì¸¡ (ì‚¬ìš©ì ì •ì˜ ê¸°ê°„)")
            print("4. ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")
            print("5. ì¢…ë£Œ")
            
            choice = input("\nì„ íƒí•˜ì„¸ìš” (1-5): ").strip()
            
            if choice == '1':
                if self.sentiment_data is not None:
                    print("\nğŸ“Š ê°ì„± ë°ì´í„° ìš”ì•½:")
                    print(f"ì´ ê¸°ì‚¬ ìˆ˜: {len(self.sentiment_data):,}ê±´")
                    print(f"í‰ê·  ê°ì„± ì ìˆ˜: {self.sentiment_data['sentiment_score'].mean():.3f}")
                    print("\nê¸°ì—…ë³„ í†µê³„:")
                    for company in ['samsung', 'apple']:
                        data = self.sentiment_data[self.sentiment_data['company'] == company]
                        if len(data) > 0:
                            print(f"{company.upper()}: {len(data)}ê±´, í‰ê·  {data['sentiment_score'].mean():.3f}")
                else:
                    print("âŒ ê°ì„± ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            elif choice == '2':
                company = input("ê¸°ì—…ëª… ì…ë ¥ (samsung/apple): ").strip().lower()
                if company in self.lstm_models:
                    self.visualize_results(company)
                else:
                    print(f"âŒ {company} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            elif choice == '3':
                company = input("ê¸°ì—…ëª… ì…ë ¥ (samsung/apple): ").strip().lower()
                try:
                    days = int(input("ì˜ˆì¸¡ ê¸°ê°„ ì…ë ¥ (ì¼): ").strip())
                    if company in self.lstm_models and days > 0:
                        future_pred = self.predict_future_sentiment(company, days)
                        if future_pred is not None:
                            print(f"\nğŸ“ˆ {company.upper()} {days}ì¼ ì˜ˆì¸¡ ê²°ê³¼:")
                            print(f"í‰ê·  ì˜ˆì¸¡ ê°ì„±: {future_pred['predicted_sentiment'].mean():.3f}")
                            print(f"ì˜ˆì¸¡ ë²”ìœ„: {future_pred['predicted_sentiment'].min():.3f} ~ {future_pred['predicted_sentiment'].max():.3f}")
                    else:
                        print("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì…ë ¥ì…ë‹ˆë‹¤.")
                except ValueError:
                    print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            elif choice == '4':
                if self.lstm_models:
                    print("\nğŸ† ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:")
                    for company, model_info in self.lstm_models.items():
                        results = model_info['test_results']
                        print(f"{company.upper()}:")
                        print(f"  RÂ²: {results['r2']:.4f}")
                        print(f"  MAE: {results['mae']:.4f}")
                else:
                    print("âŒ í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            elif choice == '5':
                print("ğŸ‘‹ ëŒ€í™”í˜• ë¶„ì„ ëª¨ë“œë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            else:
                print("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ ì„ íƒì…ë‹ˆë‹¤.")


# ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    try:
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        data_path = r"C:\Users\jmzxc\OneDrive\ë°”íƒ• í™”ë©´\ë¹…ì¹´ì¸ì¦ˆ"
        print(f"ğŸ“ ë°ì´í„° ê²½ë¡œ: {data_path}")
        
        analyzer = BigKindsPyTorchLSTMAnalyzer(data_path)
        
        # ì „ì²´ ë¶„ì„ ì‹¤í–‰
        print("\nğŸš€ ìë™ ë¶„ì„ ì‹œì‘...")
        success = analyzer.run_complete_analysis()
        
        if success:
            print("\n" + "="*60)
            print("ğŸŠ ë¶„ì„ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
            print("="*60)
            
            # ê²°ê³¼ ìš”ì•½
            print("\nğŸ“‹ ìƒì„±ëœ ê²°ê³¼ë¬¼:")
            print("ğŸ–¼ï¸  ì‹œê°í™” íŒŒì¼:")
            for company in analyzer.lstm_models.keys():
                print(f"   - {company}_pytorch_lstm_analysis.png (ì¢…í•© ë¶„ì„)")
                print(f"   - {company}_future_prediction.png (ë¯¸ë˜ ì˜ˆì¸¡)")
            
            print("\nğŸ“„ ë¦¬í¬íŠ¸ íŒŒì¼:")
            print("   - PyTorch_LSTM_Sentiment_Analysis_Report.txt")
            
            print("\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½:")
            for company, model_info in analyzer.lstm_models.items():
                r2 = model_info['test_results']['r2']
                print(f"   - {company.upper()}: RÂ² = {r2:.3f}")
            
            # ëŒ€í™”í˜• ëª¨ë“œ ì œì•ˆ
            interactive = input("\nğŸ” ëŒ€í™”í˜• ë¶„ì„ ëª¨ë“œë¥¼ ì‹¤í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
            if interactive == 'y':
                analyzer.interactive_analysis()
            
            print("\nğŸ“š ì¶”ê°€ ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ë“¤:")
            print("analyzer.predict_future_sentiment('samsung', days=60)")
            print("analyzer.visualize_results('apple')")
            print("analyzer.sentiment_data.head()")
            print("analyzer.generate_comprehensive_report()")
            
        else:
            print("\nâŒ ë¶„ì„ ì‹¤íŒ¨")
            print("ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
            print("1. ë°ì´í„° íŒŒì¼ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
            print("2. ì—‘ì…€ íŒŒì¼ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸")
            print("3. ì¸í„°ë„· ì—°ê²° ìƒíƒœ í™•ì¸ (FinBERT ëª¨ë¸ ë‹¤ìš´ë¡œë“œ)")
            print("4. ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¤„ì´ê¸°")
    
    except KeyboardInterrupt:
        print("\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nğŸ’¥ ì˜ˆê¸°ì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        print("\nğŸ”§ ë¬¸ì œ í•´ê²° ë°©ë²•:")
        print("1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ëª¨ë‘ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸")
        print("2. Python ë²„ì „ í˜¸í™˜ì„± í™•ì¸")
        print("3. ë°ì´í„° íŒŒì¼ í˜•ì‹ í™•ì¸")


"""
ğŸ”§ ì„¤ì¹˜ í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬:
pip install torch transformers pandas numpy matplotlib seaborn scikit-learn tqdm openpyxl

ğŸ“Š í”„ë¡œì íŠ¸ ì£¼ìš” íŠ¹ì§•:
1. PyTorch ê¸°ë°˜ Bidirectional LSTM ëª¨ë¸
2. KR-FinBERT-SCë¥¼ í™œìš©í•œ í•œêµ­ì–´ ê¸ˆìœµ ë‰´ìŠ¤ ê°ì„± ë¶„ì„
3. ìë™í™”ëœ ë°ì´í„° ì „ì²˜ë¦¬ ë° ê¸°ì—… ë¶„ë¥˜
4. ì¢…í•©ì ì¸ ì‹œê°í™” (9ê°œ ì„œë¸Œí”Œë¡¯)
5. ë¯¸ë˜ ê°ì„± íŠ¸ë Œë“œ ì˜ˆì¸¡
6. ìƒì„¸í•œ ì„±ëŠ¥ ë¶„ì„ ë¦¬í¬íŠ¸
7. ëŒ€í™”í˜• ë¶„ì„ ëª¨ë“œ

ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ ë‹¬ì„±:
âœ… ë‰´ìŠ¤ ë°ì´í„° ê¸°ë°˜ ê°ì„± ë¶„ì„
âœ… LSTM ëª¨ë¸ì„ í™œìš©í•œ ì‹œê³„ì—´ ì˜ˆì¸¡
âœ… ì‚¼ì„±ì „ì/ì• í”Œ ë¹„êµ ë¶„ì„
âœ… ê°ì„± íŠ¸ë Œë“œ ì‹œê°í™”
âœ… ìë™í™”ëœ ë¦¬í¬íŠ¸ ìƒì„±

ğŸ’¡ ê°œì„  ë° í™•ì¥ ê°€ëŠ¥ ì‚¬í•­:
- ì‹¤ì‹œê°„ ë‰´ìŠ¤ API ì—°ë™
- ì£¼ê°€ ë°ì´í„°ì™€ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
- ì›¹ ëŒ€ì‹œë³´ë“œ êµ¬ì¶• (Streamlit/Dash)
- ëª¨ë¸ ì•™ìƒë¸” ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
- ì„¤ëª… ê°€ëŠ¥í•œ AI ê¸°ë²• ì ìš©
"""